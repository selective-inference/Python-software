{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eigvalsh\n",
    "import functools\n",
    "import regreg.api as rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian for Group LASSO\n",
    "\n",
    "I want to finally get a working sampler for group LASSO.\n",
    "Let $\\pi:\\mathbb{R}^p \\rightarrow \\mathbb{R}^p$ denote the proximal map \n",
    "of our penalty ${\\cal P}$.\n",
    "\n",
    "The map, $z \\mapsto (\\pi(z), z - \\pi(z))$ is a bijection from $\\mathbb{R}^p$ to\n",
    "$$\n",
    "\\left\\{(\\beta, u): u \\in \\partial {\\cal P}(\\beta) \\right\\}.\n",
    "$$\n",
    "\n",
    "Our selective change of variables can then be expressed as\n",
    "$$\n",
    "\\omega(z;{\\cal D}) = \\nabla \\ell(\\beta; {\\cal D}) + \\epsilon \\beta+ u\n",
    "= \\nabla \\ell(\\pi(z)) + \\epsilon \\pi(z) + z - \\pi(z)\n",
    "$$\n",
    "\n",
    "The Jacobian is therefore\n",
    "$$\n",
    "\\left(\\nabla^2 \\ell(\\pi(z)) + (\\epsilon - 1) \\cdot I\\right) D_z\\pi(z) + I \n",
    "$$\n",
    "\n",
    "We know that\n",
    "$D\\pi(z)$ is block diagonal with $g$ block\n",
    "$$\n",
    "D_z\\pi(z)[g,g] = D_{z_g}\\left( \\frac{z_g}{\\|z_g\\|_2}(\\|z_g\\|_2 - \\lambda_g) \\right) = \n",
    "\\begin{cases}\n",
    "0 & \\|z_g\\|_2 \\leq \\lambda_g \\\\\n",
    "I_g - \\frac{\\lambda_g}{\\|z_g\\|_2} \\left(I - \\frac{1}{\\|z_g\\|^2_2}z_g z_g^T \\right) & \\|z_g\\|_2 > \\lambda_g\n",
    "\\end{cases}\n",
    "$$\n",
    "For a given active group $g$, our plan is to condition on $z_h, h \\neq g$.\n",
    "This might be easier to express in polar coordinates. Let \n",
    "$$\n",
    "(u_g(z_g), r_g(z_g)) = \\left(z_g / \\|z_g\\|_2, \\|z_g\\|_2 - \\lambda_g\\right)\n",
    "$$\n",
    "be our group specific polar coordinates so that the\n",
    "$(g,g)$ block of $D_z(\\pi(z))$ is (when non-zero)\n",
    "$$\n",
    "I_g - \\frac{\\lambda_g}{r_g + \\lambda_g} \\left(I - u_g u_g^T \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore, keeping $z_h, h \\neq g$ in standard coordinates\n",
    "and polar coordinates for $z_g$ the matrix takes the form\n",
    "$$\n",
    "\\left( \\nabla^2 \\ell(\\pi(z)) + (\\epsilon - 1) \\cdot I \\right)  \n",
    "\\begin{pmatrix}\n",
    "I_g - \\frac{\\lambda_g}{r_g + \\lambda_g} \\left(I - u_g u_g^T \\right) & 0  & 0\\\\\n",
    "0 & \\left( I_g - \\frac{\\lambda_h}{r_h + \\lambda_h} \\left(I - u_h u_h^T \\right)\\right)_{h \\neq g \\in E} & 0 \\\\ 0 & 0 & 0\\\\\n",
    "\\end{pmatrix} + I\n",
    "= A(z) \\begin{pmatrix}\n",
    "I - \\frac{\\lambda_g}{r_g + \\lambda_g} \\left(I_g - u_g u_g^T \\right) & 0  & 0\\\\\n",
    "0 & \\left( I_h - \\frac{\\lambda_h}{r_h + \\lambda_h} \\left(I_h - u_h u_h^T \\right)\\right)_{h \\neq g} & 0\\\\ 0 & 0 & 0\n",
    "\\end{pmatrix} + I\n",
    "$$\n",
    "\n",
    "Finally, we will condition on $u_g$ as well (we could try conditioning \n",
    "on its projective direction too, I suppose).\n",
    "So, ultimately we will just need to evaluate the determinant of this matrix\n",
    "as a function of $r_g$ (and integrate over $r_g$).\n",
    "\n",
    "\n",
    "Due to the block structure, we see that the determinant\n",
    "is the determinant of the smaller matrix\n",
    "$$\n",
    "A(z)[E,E] \\begin{pmatrix}\n",
    "I - \\frac{\\lambda_g}{r_g + \\lambda_g} \\left(I_g - u_g u_g^T \\right) & 0  \\\\\n",
    "0 & \\left( I_h - \\frac{\\lambda_h}{r_h + \\lambda_h} \\left(I_h - u_hu_h^T \\right)\\right)_{h \\neq g} \n",
    "\\end{pmatrix} + I_E\n",
    "$$\n",
    "\n",
    "Evaluating this matrix at some feasible $r_g$, say $r_g^*$ (perhaps the observed value or some small $\\delta_g$)\n",
    "we see want the eigenvalues of\n",
    "$$\n",
    "A_0 \\left(D_z\\pi(z_0) + c(r_g,z_0) P(z_0) \\right)  + I\n",
    " = A_0 (D_0 + c P) + I\n",
    "$$\n",
    "where \n",
    "$$\n",
    "c(r_g, z_0) = \\lambda_g \\left(\\frac{1}{r_g^*(z_0) + \\lambda_g} - \\frac{1}{r_g + \\lambda_g}\n",
    "\\right)\n",
    "$$\n",
    "and along the line through $z_0$ keeping all but $r_g$ fixed\n",
    "$$\n",
    "c(r_g, z_0) P(z_0) = D_z\\pi(z) - D_z\\pi(z_0).\n",
    "$$\n",
    "We have used the approximation that $\\nabla^2 \\ell(\\pi(z))$ does not change\n",
    "noticably change with $r_g$ -- this is certainly true for least squares\n",
    "problems. Above $A_0$ is the matrix function $A(z_0)[E,E]$ evaluated at \n",
    "$z_0=(r_g^*, u_g, (z_h)_{h \\neq g})$ and\n",
    "$$\n",
    "P(z_0) = I - u_g u_g^T\n",
    "$$\n",
    "padded out appropriately to zero so it is of size $p$.\n",
    "We also know that only $|g|-1$ of these eigenvalues are non-zero and that\n",
    "$P$ commutes with $D_0$ (and hence $D_0^{\\pm 1/2}$ and $D_0^{-1}$ when\n",
    "these are symmetric square roots -- $D_0$ is symmetric because it is\n",
    "the Hessian of the value of a proximal problem).\n",
    "\n",
    "We want\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{det}(A_0 D_0 + c A_0 P + I) &= \n",
    "\\text{det}(D_0^{1/2} A_0 D_0^{1/2} + c D_0^{1/2} A_0 P D_0^{-1/2} + I) \\\\\n",
    "&= \\text{det}(D_0^{1/2} A_0 D_0^{1/2} + c D_0^{1/2} A_0 D_0^{-1/2} P + I) \\\\\n",
    "&= \\text{det}(D_0^{1/2} A_0 D_0^{1/2} + c D_0^{1/2} A_0 D_0^{1/2} D_0^{-1} P + I) \\\\\n",
    " &= \\text{det}(D_0^{1/2} A_0 D_0^{1/2} + I)^{-1} \\cdot \\text{det}(I + c(D_0^{1/2} A_0 D_0^{1/2} + I)^{-1}D_0^{1/2} A_0 D_0^{1/2} D_0^{-1} P)\n",
    "\\end{aligned}\n",
    "$$\n",
    "We see then that it is sufficient to find the eigenvalues of\n",
    "$$\n",
    "(D_0^{1/2} A_0 D_0^{1/2} + I)^{-1}D_0^{1/2} A_0 D_0^{1/2} D_0^{-1} P\n",
    "$$\n",
    "which is the product of two symmetric matrices. Hence all its eigenvalues are real and there are $|g|-1$ non-zero ones as the matrix $D_0^{-1}P$ is of rank $|g|-1$.\n",
    "\n",
    "Given these eigenvalues $\\gamma_j$ the determinant is\n",
    "$$\n",
    "\\text{det}(D_0^{1/2} A_0 D_0^{1/2} + I)^{-1} \\cdot \\prod_{j=1}^{|g|-1} \\left(1 + c(r_g, z_0) \\gamma_j\\right)\n",
    "$$\n",
    "and the first term will cancel in the integral.\n",
    "\n",
    "The eigenvalues of the above matrix are the top $|g|-1$ eigenvalues in\n",
    "the generalized eigenvalue problem\n",
    "$$\n",
    "D_0^{-1}Pv = \\gamma ( D_0^{1/2}A_0D_0^{1/2} + I)^{-1}  D_0^{1/2}A_0D_0^{1/2}v.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Lastly, we should calculate $D_0^{1/2}$. It is enough just to compute one block, i.e.\n",
    "what is the symmetric square-root of\n",
    "$$\n",
    "\\begin{aligned}\n",
    "I - \\frac{\\lambda}{\\lambda + r} \\left(I - u u^T\\right) &= uu^T + \\left(1 - \\frac{\\lambda}{\\lambda + r}\\right) I - uu^T \\\\\n",
    "&= uu^T + \\frac{r}{\\lambda + r}\\left(I - uu^T \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence\n",
    "$$\n",
    "\\left(I - \\frac{\\lambda}{\\lambda + r} \\left(I - u u^T\\right)\\right)^{1/2} = uu^T + \\left(\\frac{r}{\\lambda+r}\\right)^{1/2}\\left(I - uu^T\\right) = \\left(\\frac{r}{\\lambda+r}\\right)^{1/2}I + \\left(1 - \\left(\\frac{r}{\\lambda+r}\\right)^{1/2}\\right) uu^T +  \n",
    "$$\n",
    "\n",
    "Also,\n",
    "$$\n",
    "\\left(I - \\frac{\\lambda}{\\lambda + r} \\left(I - u u^T\\right)\\right)^{-1} = uu^T + \\left(\\frac{\\lambda}{r} + 1 \\right) (I - uu^T)\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "D_0^{-1}P = \\begin{pmatrix} \\frac{\\lambda_g + r^*_g}{r^*_g} (I_g - u_g u_g^T) & 0 \\\\ 0 & 0 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Going back to our generalized eigenvalue problem, we note a few things.\n",
    "First, when $|g|=1$, all eigenvalues are 0. Second, we note that\n",
    "any eigenvectors in this problem must be in $\\text{row}(P) = \\text{row}(I_g-u_gu_g^T) \\subset \\text{row}(I_g)$. Let $WW^T=I_g-u_gu_g^T$. Writing $v=WW^Tv$ and setting $u=W^Tv$, the \n",
    "equation for the generalized eigenvalue problem reads\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_0^{-1}PWu = \\gamma ( D_0^{1/2}A_0D_0^{1/2} + I)^{-1}  D_0^{1/2}A_0D_0^{1/2}Wu.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Multiplying both sides by $W^T$ yields\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W^TD_0^{-1}PWu &= \\frac{\\lambda_g+ r^*_g}{r^*_g}  u \\\\\n",
    "&= \\gamma W^T ( D_0^{1/2}A_0D_0^{1/2} + I)^{-1}  D_0^{1/2}A_0D_0^{1/2}Wu.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Or, $u$ is a (regular) eigenvector of \n",
    "$$\n",
    "W^T ( D_0^{1/2}A_0D_0^{1/2} + I)^{-1}  D_0^{1/2}A_0D_0^{1/2}W\n",
    "$$\n",
    "with eigenvalue \n",
    "$$\n",
    "\\frac{\\lambda_g + r^*_g}{\\gamma r^*_g}.$$\n",
    "\n",
    "Let $\\tilde{\\gamma}$ denote the (regular) eigenvalues of $W^T ( D_0^{1/2}A_0D_0^{1/2} + I)^{-1}  D_0^{1/2}A_0D_0^{1/2}W$ (which do not depend on $r_g$ -- they depend only on $z_0$ which uses $r_g^*$ instead of $r_g$). We then have the relation\n",
    "$$\n",
    "\\gamma_j = \\frac{\\lambda_g + r_g^*}{\\tilde{\\gamma}_j r^*_g}.\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "c(r_g, z_0) \\gamma_j = \\frac{\\lambda_g}{r_g^* \\tilde{\\gamma}_j} \\frac{r_g - r_g^*}{r_g+\\lambda_g}.$$\n",
    "\n",
    "The ultimate determinant should not depend on the value $r_g^*$ chosen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using $W$ we could use $\\tilde{W}$ for which $\\tilde{W}\\tilde{W}^T=I_g$ to form the matrix\n",
    "$$\n",
    "\\tilde{W}^T(D_0^{1/2}A_0D_0^{1/2}+I)^{-1}D_0^{1/2}A_0D_0^{1/2}\\tilde{W}\n",
    "$$\n",
    "then multiply on left and right by $P$. This will yield a $|g| \\times |g|$ matrix with a 0 eigenvalue (corresponding to an eigenvector $u$). Of course, we can take $\\tilde{W}$ to be just the $g$ selector matrix.\n",
    "Finally, we take the top $|g|-1$ eigenvalues of this matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jacobian(hessian, soln, group_lasso_penalty, group_id=None, tol=1.e-6, ff=1):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    hessian : $A_0$ above\n",
    "    \n",
    "    group_id : a group index of group_lasso_penalty\n",
    "    \n",
    "    group_norm : $\\lambda_g$ above\n",
    "    \n",
    "    group_direction : $u_g$ above\n",
    "    \n",
    "    base_point: $r_g$ above\n",
    "    \n",
    "    Compute generalized eigenvalues above and return\n",
    "    function to evaluate jacobian as a function of $r_g=\\|z_g\\|_2$\n",
    "    fixing everything in the optimization variables except $r_g$.\n",
    "    \n",
    "    Above, $A_0$ is the Hessian of loss evaluated at an appropriate point.\n",
    "    '''\n",
    "    H, pen = hessian, group_lasso_penalty       # shorthand \n",
    "    nz = soln != 0                              # nonzero\n",
    "    nnz = nz.sum()                              # num nonzero\n",
    "    Hr = np.zeros((nnz, nnz))                            # restricted hessian   \n",
    "    sqrt_block = np.zeros((nnz, nnz))\n",
    "    group_idx = pen.groups == group_id\n",
    "    nz_groups = []\n",
    "\n",
    "    for idx in np.unique(pen.groups):\n",
    "        group_idx = pen.groups == idx\n",
    "        group_soln = soln[pen.groups == idx]\n",
    "        is_nz = np.linalg.norm(group_soln) > tol * np.linalg.norm(soln)\n",
    "        if is_nz:\n",
    "            ng = group_idx.sum()\n",
    "            group_direction = u_g = group_soln / np.linalg.norm(group_soln)\n",
    "            group_norm = r_g = ff * np.linalg.norm(group_soln)   # really r_g^*\n",
    "            group_weight = lambda_g = pen.weights[idx]\n",
    "            \n",
    "            fraction = np.sqrt(r_g / (lambda_g + r_g))\n",
    "            # one of the blocks in D_0^{1/2}\n",
    "            group_block = np.identity(ng) * fraction + (1 - fraction) * np.multiply.outer(u_g, u_g)\n",
    "            group_P = np.identity(ng) - np.multiply.outer(u_g, u_g)\n",
    "            nz_groups.append((idx, # a group index g\n",
    "                              group_idx, # indices where group==idx\n",
    "                              group_block, \n",
    "                              group_P,\n",
    "                              r_g,          \n",
    "                              lambda_g)\n",
    "                            )\n",
    "            \n",
    "    # setup the block hessian Hr=D_0^{1/2}A_0D_0^{1/2}\n",
    "    \n",
    "    ctr_g = 0\n",
    "    for group_g in nz_groups:\n",
    "        which_idx_g, block_g = group_g[1], group_g[2]\n",
    "        idx_g = slice(ctr_g, ctr_g + which_idx_g.sum())\n",
    "        ctr_h = 0\n",
    "        for group_h in nz_groups:\n",
    "            which_idx_h, block_h = group_h[1], group_h[2]\n",
    "            idx_h = slice(ctr_h, ctr_h + which_idx_h.sum())\n",
    "            Hr[idx_g][:,idx_h] += block_g.dot(H[which_idx_g][:,which_idx_h]).dot(block_h)\n",
    "\n",
    "    # compute (I+Hr)^{-1}Hr\n",
    "    \n",
    "    final_Q = np.linalg.inv(np.identity(Hr.shape[0]) + Hr).dot(Hr)\n",
    "    \n",
    "    ctr_g = 0\n",
    "    factors = []\n",
    "    determinants = {}\n",
    "    for group_g in nz_groups:\n",
    "        which_g, which_idx_g, _, P_g, r_g, lambda_g = group_g\n",
    "        if which_idx_g.sum() > 1:\n",
    "            idx_g = slice(ctr_g, ctr_g + which_idx_g.sum())\n",
    "            block_g = final_Q[idx_g][:,idx_g]\n",
    "            block_g = P_g.dot(block_g).dot(P_g)\n",
    "            eigvals_g = np.linalg.eigvalsh(block_g)[1:]               # \\tilde{\\gamma}'s\n",
    "            factors_g = lambda_g / (eigvals_g * r_g)           # factors in the determinant\n",
    "            def det_g(factors_g, r_g, r):\n",
    "                return np.prod(1 + np.multiply.outer(factors_g, r - r_g) / \n",
    "                               np.add.outer(lambda_g * \n",
    "                                            np.ones_like(factors_g), r), 0)\n",
    "            det_g = functools.partial(det_g, factors_g, r_g)\n",
    "        else: \n",
    "            det_g = lambda r: np.ones_like(r)\n",
    "        \n",
    "        determinants[which_g] = det_g\n",
    "\n",
    "    return determinants\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 1.  1.  1.  1.]\n",
      "3 [ 2.10153781  3.01665312  3.66178722  4.49339337]\n",
      "5 [ 1.  1.  1.  1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "groups = [1]*5 + [2]*10 + [3]*3 + [4]*6 + [5]*1\n",
    "group_weights = {1:0, 2:1, 3:3.5, 4:2, 5:0.2}\n",
    "pen = rr.group_lasso(groups, group_weights, lagrange=1)\n",
    "soln = np.zeros(pen.shape)\n",
    "soln[:5] = np.random.standard_normal(5)\n",
    "soln[15:18] = np.random.standard_normal(3)\n",
    "soln[-1] = 2.\n",
    "pen.groups\n",
    "\n",
    "p = pen.shape[0]\n",
    "n = 100\n",
    "X = np.random.standard_normal((n, p))\n",
    "H = X.T.dot(X)\n",
    "\n",
    "V0 = jacobian(H, soln, pen)\n",
    "for i in V0.keys():\n",
    "    print(i, V0[i](np.array([3.,4., 5., 7.])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking with a fudge factor to choose a different $r_g^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [ 0.55481405  0.5548513   0.55487352  0.55489881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "soln = np.zeros(pen.shape)\n",
    "soln[15:18] = np.random.standard_normal(3)\n",
    "V0 = jacobian(H, soln, pen)\n",
    "\n",
    "V1 = jacobian(H, soln, pen, ff=1.5)\n",
    "for i in V0.keys():\n",
    "    print(i, V1[i](np.array([3.,4., 5., 7.]))/ V0[i](np.array([3.,4., 5., 7.])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General penalties\n",
    "\n",
    "What we used crucially here to get into a generalized eigenvalue problem\n",
    "with symmetric matrices (i.e. real eigenvalues) was that $D_0$ commutes with $P$. If we want to condition on\n",
    "some function of optimization variables for general penalties (that are support functions of $K$) this property is not guaranteed. We will typically condition on the subgradient $u$ which\n",
    "fixes $N_uK$ and its dimension $d(u)$. Suppose we want to condition on $d(u)-1$ linear functions of the normal vector $\\beta$ -- this will correspond\n",
    "to taking an affine ray through $\\beta_0$ the observed $\\beta$. We will need that\n",
    "the Hessian of the prox along the ray $\\beta_{obs} + t \\alpha$ all have the same eigenspace. One direction $\\alpha$ that satisfies this is $\\alpha=\\beta/\\|\\beta\\|_2$. In the case $K$ is a product like the group LASSO we can find other examples. \n",
    "\n",
    "We also used the fact that $D_0$ was invertible. Generally the Hessian of the prox is not invertible, but it is invertible on the space spanned by its non-zero eigenvectors. This is what we used here in reducing the large block to a smaller block. Such a reduction will work generally -- under the assumption that $D_0$ and $P$ share the same eigenvectors corresponding to eigenvalue 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective density\n",
    "\n",
    "Finally, let's pick a target and see how to compute appropriate reference densities.\n",
    "\n",
    "For group $g$, let $J'_g(r_g)=  J'_g(r_g;u, r_g^*, (\\beta_h)_{h \\neq g \\in E}); $ denote the determinant above. The map to polar coordinates picks up an extra factor of $(\\lambda_g + r_g )^{|g|-1}$.\n",
    "\n",
    "Let $$\n",
    "\\beta(r_g) = \\beta(r_g;u_g, (\\beta_h)_{h \\neq g \\in E}) = \\begin{pmatrix} r_g u_g \\\\ (\\beta_h)_{h \\neq g \\in E} = \n",
    "\\alpha_g r_g + \\kappa_g\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "We consider Gaussian randomization $\\omega$ having precision $\\Theta$, and write\n",
    "$$\n",
    "\\ell(\\beta) = \\ell(\\bar{\\beta}) + Q(\\bar{\\beta})(\\beta- \\bar{\\beta}) = \\ell(\\bar{\\beta}) -Q(\\bar{\\beta})\\bar{\\beta} + Q\\beta\n",
    "$$\n",
    "where $\\ell(\\bar{\\beta})=0$.\n",
    "The quantity $\\ell(\\bar{\\beta}) - Q(\\bar{\\beta})\\bar{\\beta}$ is asymptotically equivalent (OK, low dim) to $\\ell(\\beta^*) - Q(\\beta^*)\\beta^*$ and is exactly $-X^TY$ in the linear regression setting. It is this quantity\n",
    "we linearly decompose as\n",
    "$$\n",
    "Q\\bar{\\beta} = N + AT.\n",
    "$$\n",
    "\n",
    "Hence, our reference distribution under $N(\\mu, \\Sigma)$ for target $T_g$ is proportional to (starting to drop $g$'s and $|g|=k$)\n",
    "$$\n",
    "\\phi_{(\\mu,\\Sigma)}(T) J'(r) (\\lambda + r)^{k-1} \\exp \\left(-\\frac{1}{2}\\left(-N-AT+Q(\\alpha r + \\kappa)+u\\right) \\Theta \\left(-N-AT+Q(\\alpha r + \\kappa)+u\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional on $(T, N, \\alpha, u, \\kappa)$  this is (as a function of $r$) proportional to \n",
    "$$\n",
    "J'(r) (\\lambda + r)^{k-1} \\exp\\left(-\\frac{r^2 \\alpha^TQ\\Theta Q\\alpha}{2} + (N+AT-Q\\kappa-u)^T\\Theta Q\\alpha r\\right)\n",
    "1_{(0,\\infty)}(r)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $k=1$, this is a Gaussian density with variance\n",
    "$$\n",
    "\\frac{1}{\\alpha^TQ\\Theta Q\\alpha}\n",
    "$$\n",
    "and mean\n",
    "$$\n",
    "\\frac{(N+AT-Q\\kappa-u)\\Theta Q\\alpha}{\\alpha^TQ\\Theta Q\\alpha}.\n",
    "$$\n",
    "\n",
    "Hence, the normalization is just\n",
    "$$\n",
    "1 - \\Phi \\left(-\\frac{(N+AT-Q\\kappa-u)\\Theta Q\\alpha}{(\\alpha^TQ\\Theta Q\\alpha)^{1/2}}\\right).\n",
    "$$\n",
    "\n",
    "Therefore, for $k=1$ the appropriate reference density for target $T$ is proportional to\n",
    "$$\n",
    "t \\mapsto \\phi_{(\\mu,\\Sigma})(t) \\cdot \\left(1 - \\Phi \\left(-\\frac{(N+AT-Q\\kappa-u)\\Theta Q\\alpha}{(\\alpha^TQ\\Theta Q\\alpha)^{1/2}}\\right) \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $k > 1$, it is this Gaussian density, modified by the term $J'(r)(\\lambda+r)^{k-1}$.\n",
    "A cheap way to sample this would be to sample from the truncated Gaussian at some $T_0$ ($N$ will be fixed because we condition on it) and use importance weights.\n",
    "The appropriate reference density is proportional to\n",
    "$$\n",
    "t \\mapsto \\phi_{(\\mu,\\Sigma})(t) \\cdot \\int_0^{\\infty} J'(r) (\\lambda+r)^{k-1}\n",
    "\\exp\\left(-\\frac{r^2 \\alpha^TQ\\Theta Q\\alpha}{2} + (N + At - Q\\kappa -u)^T\\Theta Q\\alpha r\\right) \\; dr.\n",
    "$$\n",
    "or, for some $T_0$\n",
    "$$\n",
    "t \\mapsto \\phi_{(\\mu,\\Sigma})(t) \\cdot \\int_0^{\\infty} J'(r) (\\lambda+r)^{k-1} \\exp \\left((t-T_0)^TA^T\\Theta Q\\alpha r \\right)\n",
    "\\exp\\left(-\\frac{r^2 \\alpha^TQ\\Theta Q\\alpha}{2} + (N + AT_0 - Q\\kappa -u)^T\\Theta Q\\alpha r\\right) \\; dr.\n",
    "$$\n",
    "\n",
    "This second term can be evaluated as an expectation against a sample drawn from the above density at some reference $T_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-slideshow",
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
