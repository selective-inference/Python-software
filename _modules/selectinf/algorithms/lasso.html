

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Selection &mdash; Selection Documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../documentation.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms/index.html">Non-randomized algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../randomized/index.html">Randomized algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../learning/index.html">Learning selection</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">selection</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>Selection</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for selectinf.algorithms.lasso</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module contains a class `lasso`_ that implements</span>
<span class="sd">post selection for the lasso</span>
<span class="sd">as described in `post selection LASSO`_.</span>
<span class="sd">.. _covTest: http://arxiv.org/abs/1301.7161</span>
<span class="sd">.. _Kac Rice: http://arxiv.org/abs/1308.3020</span>
<span class="sd">.. _Spacings: http://arxiv.org/abs/1401.3889</span>
<span class="sd">.. _post selection LASSO: http://arxiv.org/abs/1311.6238</span>
<span class="sd">.. _sample carving: http://arxiv.org/abs/1410.2597</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">warnings</span><span class="o">,</span> <span class="nn">functools</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">copy</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">ndist</span><span class="p">,</span> <span class="n">t</span> <span class="k">as</span> <span class="n">tdist</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="k">import</span> <span class="n">block_diag</span>

<span class="kn">from</span> <span class="nn">regreg.api</span> <span class="k">import</span> <span class="p">(</span><span class="n">glm</span><span class="p">,</span>
                        <span class="n">weighted_l1norm</span><span class="p">,</span>
                        <span class="n">simple_problem</span><span class="p">,</span>
                        <span class="n">coxph</span> <span class="k">as</span> <span class="n">coxph_obj</span><span class="p">,</span>
                        <span class="n">smooth_sum</span><span class="p">,</span>
                        <span class="n">squared_error</span><span class="p">,</span>
                        <span class="n">identity_quadratic</span><span class="p">,</span>
                        <span class="n">quadratic_loss</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">.sqrt_lasso</span> <span class="k">import</span> <span class="n">solve_sqrt_lasso</span><span class="p">,</span> <span class="n">estimate_sigma</span>
<span class="kn">from</span> <span class="nn">.debiased_lasso</span> <span class="k">import</span> <span class="p">(</span><span class="n">debiasing_matrix</span><span class="p">,</span>
                             <span class="n">pseudoinverse_debiasing_matrix</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">..constraints.affine</span> <span class="k">import</span> <span class="p">(</span><span class="n">constraints</span><span class="p">,</span> 
                                  <span class="n">selection_interval</span><span class="p">,</span>
                                  <span class="n">interval_constraints</span><span class="p">,</span>
                                  <span class="n">sample_from_constraints</span><span class="p">,</span>
                                  <span class="n">gibbs_test</span><span class="p">,</span>
                                  <span class="n">stack</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">..distributions.discrete_family</span> <span class="k">import</span> <span class="n">discrete_family</span>
<span class="kn">from</span> <span class="nn">..truncated.gaussian</span> <span class="k">import</span> <span class="n">truncated_gaussian_old</span> <span class="k">as</span> <span class="n">TG</span>
<span class="kn">from</span> <span class="nn">..glm</span> <span class="k">import</span> <span class="n">pairs_bootstrap_glm</span>


<div class="viewcode-block" id="lasso"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso">[docs]</a><span class="k">class</span> <span class="nc">lasso</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for the LASSO for post-selection inference.</span>
<span class="sd">    The problem solved is</span>
<span class="sd">    .. math::</span>
<span class="sd">        \text{minimize}_{\beta} \frac{1}{2n} \|y-X\beta\|^2_2 +</span>
<span class="sd">            \lambda \|\beta\|_1</span>
<span class="sd">    where $\lambda$ is `lam`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="lasso.__init__"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">loglike</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">ignore_inactive_constraints</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new post-selection dor the LASSO problem</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loglike : `regreg.smooth.glm.glm`</span>
<span class="sd">            A (negative) log-likelihood as implemented in `regreg`.</span>
<span class="sd">        feature_weights : np.ndarray</span>
<span class="sd">            Feature weights for L-1 penalty. If a float,</span>
<span class="sd">            it is brodcast to all features.</span>
<span class="sd">        covariance_estimator : callable (optional)</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span> <span class="o">=</span> <span class="n">loglike</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
            <span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">loglike</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">feature_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">covariance_estimator</span> <span class="o">=</span> <span class="n">covariance_estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_inactive_constraints</span> <span class="o">=</span> <span class="n">ignore_inactive_constraints</span></div>

<div class="viewcode-block" id="lasso.fit"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lasso_solution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1.e-12</span><span class="p">,</span> <span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the lasso using `regreg`.</span>
<span class="sd">        This sets the attributes `soln`, `onestep` and</span>
<span class="sd">        forms the constraints necessary for post-selection inference</span>
<span class="sd">        by calling `form_constraints()`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lasso_solution : optional</span>
<span class="sd">             If not None, this is taken to be the solution</span>
<span class="sd">             of the optimization problem. No checks</span>
<span class="sd">             are done, though the implied affine</span>
<span class="sd">             constraints will generally not be satisfied.</span>
<span class="sd">        solve_args : keyword args</span>
<span class="sd">             Passed to `regreg.problems.simple_problem.solve`.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        soln : np.float</span>
<span class="sd">             Solution to lasso.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If `self` already has an attribute `lasso_solution`</span>
<span class="sd">        this will be taken to be the solution and</span>
<span class="sd">        no optimization problem will be solved. Supplying</span>
<span class="sd">        the optional argument `lasso_solution` will</span>
<span class="sd">        overwrite `self`&#39;s `lasso_solution`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_penalty</span> <span class="o">=</span> <span class="n">weighted_l1norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">,</span> <span class="n">lagrange</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lasso_solution</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lasso_solution&quot;</span><span class="p">):</span>
            <span class="n">problem</span> <span class="o">=</span> <span class="n">simple_problem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_penalty</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="o">**</span><span class="n">solve_args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">lasso_solution</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">lasso_solution</span>

        <span class="n">lasso_solution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span>  <span class="c1"># shorthand after setting it correctly above</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">lasso_solution</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">active</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">lasso_solution</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span> <span class="o">=</span> <span class="n">lasso_solution</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_active_soln</span> <span class="o">=</span> <span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
            <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span><span class="p">)</span>
            <span class="n">H_AA</span> <span class="o">=</span> <span class="n">H</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">][:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
            <span class="n">H_AAinv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H_AA</span><span class="p">)</span>
            <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">quadratic</span>
            <span class="n">G_Q</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span><span class="p">,</span> <span class="s1">&#39;grad&#39;</span><span class="p">)</span>
            <span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span><span class="p">)</span> <span class="o">+</span> <span class="n">G_Q</span>
            <span class="n">G_A</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
            <span class="n">G_I</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_G_I</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]</span>
            <span class="n">dbeta_A</span> <span class="o">=</span> <span class="n">H_AAinv</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G_A</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">onestep_estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_active_soln</span> <span class="o">-</span> <span class="n">dbeta_A</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active_penalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_penalized</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">active_penalized</span><span class="p">],</span>
                                                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span> <span class="o">*</span> <span class="n">dbeta_A</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">active_penalized</span><span class="p">],</span>
                                                <span class="n">covariance</span><span class="o">=</span><span class="n">H_AAinv</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                                <span class="mf">1.e12</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">H_AAinv</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
                                                <span class="c1"># XXX np.inf seems to fail tests</span>
                                                <span class="n">covariance</span><span class="o">=</span><span class="n">H_AAinv</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>

                <span class="c1"># inactive constraints</span>

                <span class="n">H_IA</span> <span class="o">=</span> <span class="n">H</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">][:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
                <span class="n">H_II</span> <span class="o">=</span> <span class="n">H</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">][:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]</span>
                <span class="n">inactive_cov</span> <span class="o">=</span> <span class="n">H_II</span> <span class="o">-</span> <span class="n">H_IA</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">H_AAinv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">H_IA</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">irrepresentable</span> <span class="o">=</span> <span class="n">H_IA</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">H_AAinv</span><span class="p">)</span>
                <span class="n">inactive_mean</span> <span class="o">=</span> <span class="n">irrepresentable</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="o">-</span><span class="n">G_A</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_inactive_constraints</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="o">.</span><span class="n">sum</span><span class="p">()),</span>
                                                                    <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="o">.</span><span class="n">sum</span><span class="p">())]),</span>
                                                         <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">],</span>
                                                                    <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]]),</span>
                                                         <span class="n">covariance</span><span class="o">=</span><span class="n">inactive_cov</span><span class="p">,</span>
                                                         <span class="n">mean</span><span class="o">=</span><span class="n">inactive_mean</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inactive_constraints</span><span class="p">(</span><span class="n">G_I</span><span class="p">):</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s1">&#39;inactive constraint of KKT conditions not satisfied -- perhaps need to solve with more accuracy&#39;</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance_estimator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># make full constraints</span>

                    <span class="c1"># A: active</span>
                    <span class="c1"># I: inactive</span>
                    <span class="c1"># F: full, (A,I) stacked</span>

                    <span class="n">_cov_FA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance_estimator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">onestep_estimator</span><span class="p">,</span>
                                                        <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                                                        <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">)</span>

                    <span class="n">_cov_IA</span> <span class="o">=</span> <span class="n">_cov_FA</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">):]</span>
                    <span class="n">_cov_AA</span> <span class="o">=</span> <span class="n">_cov_FA</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)]</span>

                    <span class="n">_beta_bar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onestep_estimator</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_inactive_constraints</span><span class="p">:</span>
                        <span class="c1"># X_{-E}^T(y - X_E \bar{\beta}_E)</span>

                        <span class="n">_inactive_score</span> <span class="o">=</span> <span class="o">-</span> <span class="n">G_I</span> <span class="o">-</span> <span class="n">inactive_mean</span>

                        <span class="n">_indep_linear_part</span> <span class="o">=</span> <span class="n">_cov_IA</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">_cov_AA</span><span class="p">))</span>

                        <span class="c1"># we &quot;fix&quot; _nuisance, effectively conditioning on it</span>

                        <span class="n">_nuisance</span> <span class="o">=</span> <span class="n">_inactive_score</span> <span class="o">-</span> <span class="n">_indep_linear_part</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">_beta_bar</span><span class="p">)</span>
                        <span class="n">_upper_lim</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]</span> <span class="o">-</span>
                                      <span class="n">_nuisance</span> <span class="o">-</span>
                                      <span class="n">inactive_mean</span><span class="p">)</span>
                        <span class="n">_lower_lim</span> <span class="o">=</span> <span class="p">(</span><span class="n">_nuisance</span> <span class="o">+</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]</span> <span class="o">+</span>
                                      <span class="n">inactive_mean</span><span class="p">)</span>

                        <span class="n">_upper_linear</span> <span class="o">=</span> <span class="n">_indep_linear_part</span>
                        <span class="n">_lower_linear</span> <span class="o">=</span> <span class="o">-</span><span class="n">_indep_linear_part</span>

                        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span>
                        <span class="n">_full_linear</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">C</span><span class="o">.</span><span class="n">linear_part</span><span class="p">,</span>
                                                  <span class="n">_upper_linear</span><span class="p">,</span>
                                                  <span class="n">_lower_linear</span><span class="p">])</span>

                        <span class="n">_full_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">C</span><span class="o">.</span><span class="n">offset</span><span class="p">,</span>
                                                  <span class="n">_upper_lim</span><span class="p">,</span>
                                                  <span class="n">_lower_lim</span><span class="p">])</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">_full_linear</span><span class="p">,</span>
                                                        <span class="n">_full_offset</span><span class="p">,</span>
                                                        <span class="n">covariance</span><span class="o">=</span><span class="n">_cov_AA</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="o">.</span><span class="n">covariance</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">_cov_AA</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">(</span><span class="n">_beta_bar</span><span class="p">):</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;constraints of KKT conditions on one-step estimator &#39;</span> <span class="o">+</span>
                                      <span class="s1">&#39; not satisfied -- perhaps need to solve with more&#39;</span> <span class="o">+</span>
                                      <span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_inactive_constraints</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">lasso_solution</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inactive_constraints</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span></div>

<div class="viewcode-block" id="lasso.summary"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.summary">[docs]</a>    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;twosided&#39;</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                <span class="n">compute_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">truth</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Summary table for inference adjusted for selection.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        alternative : str</span>
<span class="sd">            One of [&quot;twosided&quot;,&quot;onesided&quot;]</span>

<span class="sd">        level : float</span>
<span class="sd">            Form level*100% selective confidence intervals.</span>

<span class="sd">        compute_intervals : bool</span>
<span class="sd">            Should we compute confidence intervals?</span>

<span class="sd">        truth : np.array</span>
<span class="sd">            True values of each beta for selected variables. If not None, a column &#39;pval&#39; are p-values</span>
<span class="sd">            computed under these corresponding null hypotheses.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pval_summary : np.recarray</span>
<span class="sd">            Array with one entry per active variable.</span>
<span class="sd">            Columns are &#39;variable&#39;, &#39;pval&#39;, &#39;lasso&#39;, &#39;onestep&#39;, &#39;lower_trunc&#39;, &#39;upper_trunc&#39;, &#39;sd&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">alternative</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;twosided&#39;</span><span class="p">,</span> <span class="s1">&#39;onesided&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;alternative must be one of [&#39;twosided&#39;, &#39;onesided&#39;]&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">truth</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">truth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span>
        <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">one_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onestep_estimator</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">one_step</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">eta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">one_step</span><span class="p">)</span>
                <span class="n">eta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">_alt</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;onesided&quot;</span><span class="p">:</span> <span class="s1">&#39;greater&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;twosided&#39;</span><span class="p">:</span> <span class="s2">&quot;twosided&quot;</span><span class="p">}[</span><span class="n">alternative</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">C</span><span class="o">.</span><span class="n">linear_part</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># there were some constraints</span>
                    <span class="n">_pval</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">one_step</span><span class="p">,</span> <span class="n">null_value</span><span class="o">=</span><span class="n">truth</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alternative</span><span class="o">=</span><span class="n">_alt</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">obs</span> <span class="o">=</span> <span class="p">(</span><span class="n">eta</span> <span class="o">*</span> <span class="n">one_step</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">eta</span> <span class="o">*</span> <span class="n">C</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">)))</span>
                    <span class="n">Z</span> <span class="o">=</span> <span class="n">obs</span> <span class="o">/</span> <span class="n">sd</span>
                    <span class="n">_pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ndist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>

                <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">level</span>
                <span class="k">if</span> <span class="n">compute_intervals</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">C</span><span class="o">.</span><span class="n">linear_part</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># there were some constraints</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">_interval</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">one_step</span><span class="p">,</span>
                                                   <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">OverflowError</span><span class="p">:</span>
                            <span class="n">_interval</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                        <span class="n">_interval</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">_interval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                            <span class="n">_interval</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">_interval</span> <span class="o">=</span> <span class="p">(</span><span class="n">obs</span> <span class="o">-</span> <span class="n">ndist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sd</span><span class="p">,</span>
                                     <span class="n">obs</span> <span class="o">+</span> <span class="n">ndist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sd</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_interval</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span>
                <span class="n">_bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">bounds</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">one_step</span><span class="p">))</span>
                <span class="n">sd</span> <span class="o">=</span> <span class="n">_bounds</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">lower_trunc</span><span class="p">,</span> <span class="n">est</span><span class="p">,</span> <span class="n">upper_trunc</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">_bounds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                               <span class="n">_pval</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
                               <span class="n">one_step</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                               <span class="n">_interval</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                               <span class="n">_interval</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                               <span class="n">lower_trunc</span><span class="p">,</span>
                               <span class="n">upper_trunc</span><span class="p">,</span>
                               <span class="n">sd</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                          <span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">([(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;pval&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;lasso&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;onestep&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;lower_confidence&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;upper_confidence&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;lower_trunc&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;upper_trunc&#39;</span><span class="p">,</span>
                                                             <span class="s1">&#39;sd&#39;</span><span class="p">],</span>
                                                            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)]))</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">soln</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solution to the lasso problem, set by `fit` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lasso_solution&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Affine constraints for this LASSO problem.</span>
<span class="sd">        These are the constraints determined only</span>
<span class="sd">        by the active block.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span>

<div class="viewcode-block" id="lasso.gaussian"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.gaussian">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">gaussian</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">Y</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Squared-error LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \frac{1}{2} \|Y-X\beta\|^2_2 + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\lambda$ is `feature_weights`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        Y : ndarray</span>
<span class="sd">            Shape (n,) -- the response.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        sigma : float (optional)</span>
<span class="sd">            Noise variance. Set to 1 if `covariance_estimator` is not None.</span>
<span class="sd">            This scales the loglikelihood by `sigma**(-2)`.</span>
<span class="sd">        covariance_estimator : callable (optional)</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of some of the</span>
<span class="sd">        rows and columns of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">covariance_estimator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">covariance_estimator</span><span class="p">)</span></div>

<div class="viewcode-block" id="lasso.logistic"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.logistic">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">logistic</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span> 
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">successes</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Logistic LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \ell(X\beta) + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\ell$ is the negative of the logistic</span>
<span class="sd">        log-likelihood (half the logistic deviance)</span>
<span class="sd">        and $\lambda$ is `feature_weights`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        successes : ndarray</span>
<span class="sd">            Shape (n,) -- response vector. An integer number of successes.</span>
<span class="sd">            For data that is proportions, multiply the proportions</span>
<span class="sd">            by the number of trials first.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        trials : ndarray (optional)</span>
<span class="sd">            Number of trials per response, defaults to</span>
<span class="sd">            ones the same shape as Y.</span>
<span class="sd">        covariance_estimator : optional</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">successes</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="n">trials</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span>
                     <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">covariance_estimator</span><span class="p">)</span></div>

<div class="viewcode-block" id="lasso.coxph"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.coxph">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">coxph</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
              <span class="n">X</span><span class="p">,</span>
              <span class="n">times</span><span class="p">,</span>
              <span class="n">status</span><span class="p">,</span>
              <span class="n">feature_weights</span><span class="p">,</span>
              <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cox proportional hazards LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \ell^{\text{Cox}}(\beta) + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\ell^{\text{Cox}}$ is the</span>
<span class="sd">        negative of the log of the Cox partial</span>
<span class="sd">        likelihood and $\lambda$ is `feature_weights`.</span>
<span class="sd">        Uses Efron&#39;s tie breaking method.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        times : ndarray</span>
<span class="sd">            Shape (n,) -- the survival times.</span>
<span class="sd">        status : ndarray</span>
<span class="sd">            Shape (n,) -- the censoring status.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        covariance_estimator : optional</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">coxph_obj</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">times</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span>
                     <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">covariance_estimator</span><span class="p">)</span></div>

<div class="viewcode-block" id="lasso.poisson"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.poisson">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">poisson</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">counts</span><span class="p">,</span>
                <span class="n">feature_weights</span><span class="p">,</span>
                <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Poisson log-linear LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \ell^{\text{Poisson}}(\beta) + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\ell^{\text{Poisson}}$ is the negative</span>
<span class="sd">        of the log of the Poisson likelihood (half the deviance)</span>
<span class="sd">        and $\lambda$ is `feature_weights`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        counts : ndarray</span>
<span class="sd">            Shape (n,) -- the response.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        covariance_estimator : optional</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span>
                     <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">covariance_estimator</span><span class="p">)</span></div>

<div class="viewcode-block" id="lasso.sqrt_lasso"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.lasso.sqrt_lasso">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">sqrt_lasso</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                   <span class="n">X</span><span class="p">,</span>
                   <span class="n">Y</span><span class="p">,</span>
                   <span class="n">feature_weights</span><span class="p">,</span>
                   <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">covariance</span><span class="o">=</span><span class="s1">&#39;parametric&#39;</span><span class="p">,</span>
                   <span class="n">sigma_estimate</span><span class="o">=</span><span class="s1">&#39;truncated&#39;</span><span class="p">,</span>
                   <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use sqrt-LASSO to choose variables.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \|Y-X\beta\|_2 + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\lambda$ is `feature_weights`. After solving the problem</span>
<span class="sd">        treat as if `gaussian` with implied variance and choice of</span>
<span class="sd">        multiplier. See arxiv.org/abs/1504.08031 for details.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        Y : ndarray</span>
<span class="sd">            Shape (n,) -- the response.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        covariance : str</span>
<span class="sd">            One of &#39;parametric&#39; or &#39;sandwich&#39;. Method</span>
<span class="sd">            used to estimate covariance for inference</span>
<span class="sd">            in second stage.</span>
<span class="sd">        sigma_estimate : str</span>
<span class="sd">            One of &#39;truncated&#39; or &#39;OLS&#39;. Method</span>
<span class="sd">            used to estimate $\sigma$ when using</span>
<span class="sd">            parametric covariance.</span>
<span class="sd">        solve_args : dict</span>
<span class="sd">            Arguments passed to solver.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Unlike other variants of LASSO, this</span>
<span class="sd">        solves the problem on construction as the active</span>
<span class="sd">        set is needed to find equivalent gaussian LASSO.</span>
<span class="sd">        Assumes parametric model is correct for inference,</span>
<span class="sd">        i.e. does not accept a covariance estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
            <span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">feature_weights</span>
        <span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span>

        <span class="c1"># TODO: refits sqrt lasso more than once -- make an override for avoiding refitting?</span>

        <span class="n">soln</span> <span class="o">=</span> <span class="n">solve_sqrt_lasso</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">feature_weights</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="n">solve_args</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># find active set, and estimate of sigma</span>

        <span class="n">active</span> <span class="o">=</span> <span class="p">(</span><span class="n">soln</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">nactive</span> <span class="o">=</span> <span class="n">active</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">nactive</span><span class="p">:</span>

            <span class="n">subgrad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">soln</span><span class="p">[</span><span class="n">active</span><span class="p">])</span> <span class="o">*</span> <span class="n">feature_weights</span><span class="p">[</span><span class="n">active</span><span class="p">]</span>
            <span class="n">X_E</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">active</span><span class="p">]</span>
            <span class="n">X_Ei</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_E</span><span class="p">)</span>
            <span class="n">sigma_E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">X_E</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">nactive</span><span class="p">)</span>
            <span class="n">multiplier</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="n">nactive</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X_Ei</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">subgrad</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

            <span class="c1"># check truncation interval for sigma_E</span>

            <span class="c1"># the KKT conditions imply an inequality like</span>
            <span class="c1"># \hat{\sigma}_E \cdot LHS \leq RHS</span>

            <span class="n">penalized</span> <span class="o">=</span> <span class="n">feature_weights</span><span class="p">[</span><span class="n">active</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="n">penalized</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                <span class="n">D_E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">soln</span><span class="p">[</span><span class="n">active</span><span class="p">][</span><span class="n">penalized</span><span class="p">])</span>  <span class="c1"># diagonal matrix of signs</span>
                <span class="n">LHS</span> <span class="o">=</span> <span class="n">D_E</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X_E</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_E</span><span class="p">),</span> <span class="n">subgrad</span><span class="p">)[</span><span class="n">penalized</span><span class="p">]</span>
                <span class="n">RHS</span> <span class="o">=</span> <span class="n">D_E</span> <span class="o">*</span> <span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">)[</span><span class="n">penalized</span><span class="p">]</span>

                <span class="n">ratio</span> <span class="o">=</span> <span class="n">RHS</span> <span class="o">/</span> <span class="n">LHS</span>

                <span class="n">group1</span> <span class="o">=</span> <span class="n">LHS</span> <span class="o">&gt;</span> <span class="mi">0</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
                <span class="k">if</span> <span class="n">group1</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                    <span class="n">upper_bound</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">ratio</span><span class="p">[</span><span class="n">group1</span><span class="p">]))</span>  <span class="c1"># necessarily these will have RHS &gt; 0</span>

                <span class="n">group2</span> <span class="o">=</span> <span class="p">((</span><span class="n">LHS</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> 
                          <span class="p">(</span><span class="n">RHS</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">))</span>  <span class="c1"># we can ignore the other possibility since this gives a lower bound of 0</span>
                <span class="n">lower_bound</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="n">group2</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                    <span class="n">lower_bound</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">lower_bound</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratio</span><span class="p">[</span><span class="n">group2</span><span class="p">]))</span>

                <span class="n">upper_bound</span> <span class="o">/=</span> <span class="n">multiplier</span>
                <span class="n">lower_bound</span> <span class="o">/=</span> <span class="n">multiplier</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">lower_bound</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

            <span class="n">_sigma_estimator_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">sigma_E</span><span class="p">,</span>
                                     <span class="n">n</span> <span class="o">-</span> <span class="n">nactive</span><span class="p">,</span>
                                     <span class="n">lower_bound</span><span class="p">,</span>
                                     <span class="n">upper_bound</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sigma_estimate</span> <span class="o">==</span> <span class="s1">&#39;truncated&#39;</span><span class="p">:</span>
                <span class="n">_sigma_hat</span> <span class="o">=</span> <span class="n">estimate_sigma</span><span class="p">(</span><span class="o">*</span><span class="n">_sigma_estimator_args</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">sigma_estimate</span> <span class="o">==</span> <span class="s1">&#39;OLS&#39;</span><span class="p">:</span>
                <span class="n">_sigma_hat</span> <span class="o">=</span> <span class="n">sigma_E</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;sigma_estimate must be one of [&quot;truncated&quot;, &quot;OLS&quot;]&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_sigma_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">multiplier</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">sigma_E</span> <span class="o">=</span> <span class="n">_sigma_hat</span>

        <span class="c1"># XXX how should quadratic be changed?</span>
        <span class="c1"># multiply everything by sigma_E?</span>

        <span class="k">if</span> <span class="n">quadratic</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">qc</span> <span class="o">=</span> <span class="n">quadratic</span><span class="o">.</span><span class="n">collapsed</span><span class="p">()</span>
            <span class="n">qc</span><span class="o">.</span><span class="n">coef</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">nactive</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma_E</span>
            <span class="n">qc</span><span class="o">.</span><span class="n">linear_term</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">nactive</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma_E</span>
            <span class="n">quadratic</span> <span class="o">=</span> <span class="n">qc</span>

        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">covariance</span> <span class="o">==</span> <span class="s1">&#39;parametric&#39;</span><span class="p">:</span>
            <span class="n">cov_est</span> <span class="o">=</span> <span class="n">glm_parametric_estimator</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">dispersion</span><span class="o">=</span><span class="n">_sigma_hat</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">covariance</span> <span class="o">==</span> <span class="s1">&#39;sandwich&#39;</span><span class="p">:</span>
            <span class="n">cov_est</span> <span class="o">=</span> <span class="n">glm_sandwich_estimator</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;covariance must be one of [&quot;parametric&quot;, &quot;sandwich&quot;]&#39;</span><span class="p">)</span>

        <span class="n">L</span> <span class="o">=</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span> <span class="o">*</span> <span class="n">multiplier</span> <span class="o">*</span> <span class="n">sigma_E</span><span class="p">,</span>
                  <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">cov_est</span><span class="p">,</span>
                  <span class="n">ignore_inactive_constraints</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># these arguments are reused for data carving</span>

        <span class="k">if</span> <span class="n">nactive</span><span class="p">:</span>
            <span class="n">L</span><span class="o">.</span><span class="n">_sigma_hat</span> <span class="o">=</span> <span class="n">_sigma_hat</span>
            <span class="n">L</span><span class="o">.</span><span class="n">_sigma_estimator_args</span> <span class="o">=</span> <span class="n">_sigma_estimator_args</span>
            <span class="n">L</span><span class="o">.</span><span class="n">_weight_multiplier</span> <span class="o">=</span> <span class="n">multiplier</span> <span class="o">*</span> <span class="n">sigma_E</span>
            <span class="n">L</span><span class="o">.</span><span class="n">_multiplier</span> <span class="o">=</span> <span class="n">multiplier</span>
            <span class="n">L</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">soln</span>

        <span class="k">return</span> <span class="n">L</span></div></div>


<div class="viewcode-block" id="nominal_intervals"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.nominal_intervals">[docs]</a><span class="k">def</span> <span class="nf">nominal_intervals</span><span class="p">(</span><span class="n">lasso_obj</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Intervals for OLS parameters of active variables</span>
<span class="sd">    that have not been adjusted for selection.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">unadjusted_intervals</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">level</span>
    <span class="k">if</span> <span class="n">lasso_obj</span><span class="o">.</span><span class="n">active</span> <span class="ow">is</span> <span class="ow">not</span> <span class="p">[]:</span>
        <span class="n">SigmaE</span> <span class="o">=</span> <span class="n">lasso_obj</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">covariance</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lasso_obj</span><span class="o">.</span><span class="n">active</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">lasso_obj</span><span class="o">.</span><span class="n">onestep_estimator</span><span class="p">)</span>
            <span class="n">eta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">lasso_obj</span><span class="o">.</span><span class="n">onestep_estimator</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">ndist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigmaE</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
            <span class="n">_interval</span> <span class="o">=</span> <span class="p">[</span><span class="n">center</span> <span class="o">-</span> <span class="n">width</span><span class="p">,</span> <span class="n">center</span> <span class="o">+</span> <span class="n">width</span><span class="p">]</span>
            <span class="n">unadjusted_intervals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">lasso_obj</span><span class="o">.</span><span class="n">active</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">eta</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span>
                                         <span class="n">_interval</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">unadjusted_intervals</span></div>


<div class="viewcode-block" id="glm_sandwich_estimator"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.glm_sandwich_estimator">[docs]</a><span class="k">def</span> <span class="nf">glm_sandwich_estimator</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bootstrap estimator of covariance of</span>

<span class="sd">    .. math::</span>

<span class="sd">        (\bar{\beta}_E, X_{-E}^T(y-X_E\bar{\beta}_E)</span>
<span class="sd">    the OLS estimator of population regression</span>
<span class="sd">    coefficients and inactive correlation with the</span>
<span class="sd">    OLS residuals.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    estimator : callable</span>
<span class="sd">        Takes arguments (beta, active, inactive)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_estimator</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">active</span><span class="p">,</span> <span class="n">inactive</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># shorthand</span>

        <span class="n">beta_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">beta_full</span><span class="p">[</span><span class="n">active</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>

        <span class="c1"># make sure active / inactive are bool</span>

        <span class="n">active_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="n">active_bool</span><span class="p">[</span><span class="n">active</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">inactive_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="n">inactive_bool</span><span class="p">[</span><span class="n">inactive</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">bootstrapper</span> <span class="o">=</span> <span class="n">pairs_bootstrap_glm</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span>
                                           <span class="n">active_bool</span><span class="p">,</span>
                                           <span class="n">beta_full</span><span class="o">=</span><span class="n">beta_full</span><span class="p">,</span>
                                           <span class="n">inactive</span><span class="o">=</span><span class="n">inactive_bool</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">nactive</span> <span class="o">=</span> <span class="n">active_bool</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">first_moment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">second_moment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">nactive</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">Z_star</span> <span class="o">=</span> <span class="n">bootstrapper</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">first_moment</span> <span class="o">+=</span> <span class="n">Z_star</span>
            <span class="n">second_moment</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">Z_star</span><span class="p">,</span> <span class="n">Z_star</span><span class="p">[:</span><span class="n">nactive</span><span class="p">])</span>

        <span class="n">first_moment</span> <span class="o">/=</span> <span class="n">B</span>
        <span class="n">second_moment</span> <span class="o">/=</span> <span class="n">B</span>

        <span class="n">cov</span> <span class="o">=</span> <span class="n">second_moment</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">first_moment</span><span class="p">,</span>
                                                <span class="n">first_moment</span><span class="p">[:</span><span class="n">nactive</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">cov</span>

    <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_estimator</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span></div>


<div class="viewcode-block" id="glm_parametric_estimator"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.glm_parametric_estimator">[docs]</a><span class="k">def</span> <span class="nf">glm_parametric_estimator</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">dispersion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parametric estimator of covariance of</span>

<span class="sd">    .. math::</span>

<span class="sd">        (\bar{\beta}_E, X_{-E}^T(y-\nabla \ell(X_E\bar{\beta}_E))</span>
<span class="sd">    the OLS estimator of population regression</span>
<span class="sd">    coefficients and inactive correlation with the</span>
<span class="sd">    OLS residuals.</span>
<span class="sd">    If `sigma` is None, it computes usual unbiased estimate</span>
<span class="sd">    of variance in Gaussian model and plugs it in,</span>
<span class="sd">    assuming parametric form is correct.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    estimator : callable</span>
<span class="sd">        Takes arguments (beta, active, inactive)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_estimator</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">dispersion</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">active</span><span class="p">,</span> <span class="n">inactive</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">loglike</span><span class="o">.</span><span class="n">data</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">nactive</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active</span><span class="p">)</span>

        <span class="n">linear_predictor</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">active</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">loglike</span><span class="o">.</span><span class="n">saturated_loss</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">linear_predictor</span><span class="p">)</span>
        <span class="n">Sigma_A</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">active</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">active</span><span class="p">])</span>
        <span class="n">Sigma_Ainv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Sigma_A</span><span class="p">)</span>

        <span class="n">_unscaled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">active</span><span class="p">)))</span>
        <span class="n">_unscaled</span><span class="p">[:</span><span class="n">nactive</span><span class="p">]</span> <span class="o">=</span> <span class="n">Sigma_Ainv</span>

        <span class="c1"># the lower block is left at 0 because</span>
        <span class="c1"># under the parametric model, these pieces</span>
        <span class="c1"># are independent</span>

        <span class="c1"># if no dispersion, use Pearson&#39;s X^2</span>

        <span class="k">if</span> <span class="n">dispersion</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">active</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
            <span class="n">dispersion</span> <span class="o">=</span> <span class="p">((</span><span class="n">loglike</span><span class="o">.</span><span class="n">saturated_loss</span><span class="o">.</span><span class="n">smooth_objective</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="s1">&#39;grad&#39;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">nactive</span><span class="p">)</span>

        <span class="n">_unscaled</span> <span class="o">*=</span> <span class="n">dispersion</span> <span class="o">**</span> <span class="mi">2</span>

        <span class="k">return</span> <span class="n">_unscaled</span>

    <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_estimator</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">dispersion</span><span class="p">)</span></div>


<div class="viewcode-block" id="standard_lasso"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.standard_lasso">[docs]</a><span class="k">def</span> <span class="nf">standard_lasso</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lam_frac</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="o">**</span><span class="n">solve_args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a LASSO with a default choice of Lagrange parameter</span>
<span class="sd">    equal to `lam_frac` times $\sigma \cdot E(|X^T\epsilon|)$</span>
<span class="sd">    with $\epsilon$ IID N(0,1).</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : np.float</span>
<span class="sd">        Response vector</span>
<span class="sd">    X : np.float</span>
<span class="sd">        Design matrix</span>
<span class="sd">    sigma : np.float</span>
<span class="sd">        Noise variance</span>
<span class="sd">    lam_frac : float</span>
<span class="sd">        Multiplier for choice of $\lambda$</span>
<span class="sd">    solve_args : keyword args</span>
<span class="sd">        Passed to `regreg.problems.simple_problem.solve`.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lasso_selection : `lasso`</span>
<span class="sd">         Instance of `lasso` after fitting.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">lam_frac</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">50000</span><span class="p">))))</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">*</span> <span class="n">sigma</span>
    <span class="n">lasso_selector</span> <span class="o">=</span> <span class="n">lasso</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="n">lasso_selector</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">**</span><span class="n">solve_args</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">lasso_selector</span></div>

<div class="viewcode-block" id="data_carving"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving">[docs]</a><span class="k">class</span> <span class="nc">data_carving</span><span class="p">(</span><span class="n">lasso</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Even if a covariance estimator is supplied,</span>
<span class="sd">    we assume that we can drop inactive constraints,</span>
<span class="sd">    i.e. the same (asymptotic) independence that</span>
<span class="sd">    holds for parametric model is assumed to hold here</span>
<span class="sd">    as well.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="data_carving.__init__"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">loglike_select</span><span class="p">,</span>
                 <span class="n">loglike_inference</span><span class="p">,</span>
                 <span class="n">loglike_full</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">lasso</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loglike_select</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span> <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">covariance_estimator</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loglike_inference</span> <span class="o">=</span> <span class="n">loglike_inference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loglike_full</span> <span class="o">=</span> <span class="n">loglike_full</span></div>

<div class="viewcode-block" id="data_carving.gaussian"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.gaussian">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">gaussian</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">Y</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">stage_one</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">splitn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">split_frac</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">stage_one</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">splitn</span><span class="p">]</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">splitn</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stage_one</span><span class="p">]</span>
        <span class="n">Y1</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>
        <span class="n">Y2</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]</span>

        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">loglike1</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Y1</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">loglike2</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">Y2</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike1</span><span class="p">,</span> <span class="n">loglike2</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="data_carving.logistic"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.logistic">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">logistic</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">successes</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">stage_one</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">splitn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">split_frac</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">stage_one</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">splitn</span><span class="p">]</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">splitn</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stage_one</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">trials</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">trials</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">successes</span><span class="p">)</span>

        <span class="n">successes1</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">trials1</span> <span class="o">=</span> <span class="n">successes</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">trials</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>
        <span class="n">successes2</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">trials2</span> <span class="o">=</span> <span class="n">successes</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">trials</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]</span>

        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">successes</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="n">trials</span><span class="p">)</span>
        <span class="n">loglike1</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">successes1</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="n">trials1</span><span class="p">)</span>
        <span class="n">loglike2</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">successes2</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="n">trials2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike1</span><span class="p">,</span> <span class="n">loglike2</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="data_carving.poisson"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.poisson">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">poisson</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">counts</span><span class="p">,</span>
                <span class="n">feature_weights</span><span class="p">,</span>
                <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">stage_one</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">splitn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">split_frac</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">stage_one</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">splitn</span><span class="p">]</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">splitn</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stage_one</span><span class="p">]</span>

        <span class="n">counts1</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>
        <span class="n">counts2</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]</span>

        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">counts</span><span class="p">)</span>
        <span class="n">loglike1</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">counts1</span><span class="p">)</span>
        <span class="n">loglike2</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">counts2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike1</span><span class="p">,</span> <span class="n">loglike2</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="data_carving.coxph"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.coxph">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">coxph</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
              <span class="n">X</span><span class="p">,</span>
              <span class="n">times</span><span class="p">,</span>
              <span class="n">status</span><span class="p">,</span>
              <span class="n">feature_weights</span><span class="p">,</span>
              <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
              <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
              <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">stage_one</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">splitn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">split_frac</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">stage_one</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">splitn</span><span class="p">]</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">splitn</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stage_one</span><span class="p">]</span>

        <span class="n">times1</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">status1</span> <span class="o">=</span> <span class="n">times</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">status</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>
        <span class="n">times2</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">status2</span> <span class="o">=</span> <span class="n">times</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">status</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]</span>

        <span class="n">loglike</span> <span class="o">=</span> <span class="n">coxph_obj</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">times</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span>
        <span class="n">loglike1</span> <span class="o">=</span> <span class="n">coxph_obj</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">times1</span><span class="p">,</span> <span class="n">status1</span><span class="p">)</span>
        <span class="n">loglike2</span> <span class="o">=</span> <span class="n">coxph_obj</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">times2</span><span class="p">,</span> <span class="n">status2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike1</span><span class="p">,</span> <span class="n">loglike2</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="data_carving.sqrt_lasso"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.sqrt_lasso">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">sqrt_lasso</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                   <span class="n">X</span><span class="p">,</span>
                   <span class="n">Y</span><span class="p">,</span>
                   <span class="n">feature_weights</span><span class="p">,</span>
                   <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                   <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}):</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">stage_one</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">splitn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">split_frac</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">stage_one</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">splitn</span><span class="p">]</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">splitn</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stage_two</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stage_one</span><span class="p">]</span>

        <span class="n">Y1</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>
        <span class="n">Y2</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]</span>

        <span class="c1"># TODO: refits sqrt lasso more than once</span>

        <span class="n">L</span> <span class="o">=</span> <span class="n">lasso</span><span class="o">.</span><span class="n">sqrt_lasso</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Y1</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="n">solve_args</span><span class="p">)</span>
        <span class="n">soln</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">solve_args</span><span class="o">=</span><span class="n">solve_args</span><span class="p">)</span>
        <span class="n">_sigma_E1</span><span class="p">,</span> <span class="n">_df1</span><span class="p">,</span> <span class="n">_lower</span><span class="p">,</span> <span class="n">_upper</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">_sigma_estimator_args</span>
        <span class="n">_df2</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_two</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_df2</span><span class="p">:</span>
            <span class="n">X_E2</span> <span class="o">=</span> <span class="n">X2</span><span class="p">[:,</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
            <span class="n">_sigma_E2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y2</span> <span class="o">-</span> <span class="n">X_E2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_E2</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y2</span><span class="p">)))</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_two</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">))</span>
            <span class="n">_sigma_hat</span> <span class="o">=</span> <span class="n">estimate_sigma</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">_sigma_E1</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">_df1</span> <span class="o">+</span> <span class="n">_sigma_E2</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">_df2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">_df1</span> <span class="o">+</span> <span class="n">_df2</span><span class="p">)),</span>
                                        <span class="n">_df1</span><span class="p">,</span>
                                        <span class="n">_lower</span><span class="p">,</span>
                                        <span class="n">_upper</span><span class="p">,</span>
                                        <span class="n">untruncated_df</span><span class="o">=</span><span class="n">_df2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_sigma_hat</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">_sigma_hat</span>

        <span class="n">cov_est</span> <span class="o">=</span> <span class="n">glm_parametric_estimator</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">loglike</span><span class="p">,</span> <span class="n">dispersion</span><span class="o">=</span><span class="n">_sigma_hat</span><span class="p">)</span>

        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">loglike1</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Y1</span><span class="p">)</span>
        <span class="n">loglike2</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">Y2</span><span class="p">)</span>

        <span class="n">L</span> <span class="o">=</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike1</span><span class="p">,</span> <span class="n">loglike2</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span> <span class="o">*</span> <span class="n">L</span><span class="o">.</span><span class="n">_weight_multiplier</span><span class="p">,</span>
                  <span class="n">covariance_estimator</span><span class="o">=</span><span class="n">cov_est</span><span class="p">)</span>
        <span class="n">L</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">soln</span>
        <span class="k">return</span> <span class="n">L</span></div>

<div class="viewcode-block" id="data_carving.fit"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1.e-12</span><span class="p">,</span> <span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}):</span>

        <span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="n">solve_args</span><span class="p">)</span>

        <span class="n">n1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_full</span><span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">_feature_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">_feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">_feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="n">_unpenalized_problem</span> <span class="o">=</span> <span class="n">simple_problem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike_full</span><span class="p">,</span>
                                              <span class="n">weighted_l1norm</span><span class="p">(</span><span class="n">_feature_weights</span><span class="p">,</span> <span class="n">lagrange</span><span class="o">=</span><span class="mf">1.</span><span class="p">))</span>
        <span class="n">_unpenalized</span> <span class="o">=</span> <span class="n">_unpenalized_problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="o">**</span><span class="n">solve_args</span><span class="p">)</span>
        <span class="n">_unpenalized_active</span> <span class="o">=</span> <span class="n">_unpenalized</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>

        <span class="n">s</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_full</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">_unpenalized</span><span class="p">)</span>
            <span class="n">H_AA</span> <span class="o">=</span> <span class="n">H</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">][:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
            <span class="n">_cov_block</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H_AA</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_carve_invcov</span> <span class="o">=</span> <span class="n">H_AA</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance_estimator</span><span class="p">(</span><span class="n">_unpenalized_active</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">)</span>
            <span class="n">_cov_block</span> <span class="o">=</span> <span class="n">C</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)][:,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_carve_invcov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">_cov_block</span><span class="p">)</span>

        <span class="n">_subsample_block</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n1</span><span class="p">)</span> <span class="o">*</span> <span class="n">_cov_block</span>
        <span class="n">_carve_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">))</span>
        <span class="n">_carve_cov</span><span class="p">[:</span><span class="n">s</span><span class="p">][:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">_cov_block</span>
        <span class="n">_carve_cov</span><span class="p">[</span><span class="n">s</span><span class="p">:][:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">_subsample_block</span>
        <span class="n">_carve_cov</span><span class="p">[:</span><span class="n">s</span><span class="p">][:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">_subsample_block</span>
        <span class="n">_carve_cov</span><span class="p">[</span><span class="n">s</span><span class="p">:][:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">_subsample_block</span>

        <span class="n">_carve_linear_part</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="o">.</span><span class="n">linear_part</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">)[</span><span class="n">s</span><span class="p">:])</span>
        <span class="n">_carve_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="o">.</span><span class="n">offset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_carve_constraints</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">_carve_linear_part</span><span class="p">,</span>
                                              <span class="n">_carve_offset</span><span class="p">,</span>
                                              <span class="n">covariance</span><span class="o">=</span><span class="n">_carve_cov</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_carve_feasible</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">_unpenalized_active</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">onestep_estimator</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unpenalized_active</span> <span class="o">=</span> <span class="n">_unpenalized_active</span></div>

<div class="viewcode-block" id="data_carving.hypothesis_test"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_carving.hypothesis_test">[docs]</a>    <span class="k">def</span> <span class="nf">hypothesis_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">variable</span><span class="p">,</span>
                        <span class="n">burnin</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                        <span class="n">ndraw</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span>
                        <span class="n">compute_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">variable</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;expecting an active variable&#39;</span><span class="p">)</span>

        <span class="c1"># shorthand</span>
        <span class="n">j</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
        <span class="n">twice_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_constraints</span><span class="o">.</span><span class="n">linear_part</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">sparsity</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">twice_s</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="n">keep</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">conditioning</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_invcov</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">twice_s</span><span class="p">)[:</span><span class="n">s</span><span class="p">])[</span><span class="n">keep</span><span class="p">]</span>

        <span class="n">contrast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">contrast</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

        <span class="c1"># condition to remove dependence on nuisance parameters</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">conditional_law</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_constraints</span><span class="o">.</span><span class="n">conditional</span><span class="p">(</span><span class="n">conditioning</span><span class="p">,</span>
                                                                  <span class="n">conditioning</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_carve_feasible</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">conditional_law</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_constraints</span>

        <span class="n">observed</span> <span class="o">=</span> <span class="p">(</span><span class="n">contrast</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_feasible</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_constraints</span><span class="o">.</span><span class="n">linear_part</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">gibbs_test</span><span class="p">(</span><span class="n">conditional_law</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">_carve_feasible</span><span class="p">,</span>
                                         <span class="n">contrast</span><span class="p">,</span>
                                         <span class="n">sigma_known</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">white</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">ndraw</span><span class="o">=</span><span class="n">ndraw</span><span class="p">,</span>
                                         <span class="n">burnin</span><span class="o">=</span><span class="n">burnin</span><span class="p">,</span>
                                         <span class="n">how_often</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                         <span class="n">UMPU</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">pval</span> <span class="o">=</span> <span class="n">family</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">observed</span><span class="p">)</span>
            <span class="n">pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">pval</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">pval</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># only unpenalized coefficients were nonzero, no constraints</span>

            <span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">contrast</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_carve_constraints</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">contrast</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">/</span> <span class="n">sd</span>
            <span class="n">pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ndist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">pval</span></div></div>


<div class="viewcode-block" id="data_splitting"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_splitting">[docs]</a><span class="k">class</span> <span class="nc">data_splitting</span><span class="p">(</span><span class="n">data_carving</span><span class="p">):</span>

<div class="viewcode-block" id="data_splitting.fit"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_splitting.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1.e-12</span><span class="p">,</span> <span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">},</span> <span class="n">use_full_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">solve_args</span><span class="o">=</span><span class="n">solve_args</span><span class="p">)</span>

        <span class="n">_feature_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">_feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">_feature_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inactive</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="n">_unpenalized_problem</span> <span class="o">=</span> <span class="n">simple_problem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike_inference</span><span class="p">,</span>
                                              <span class="n">weighted_l1norm</span><span class="p">(</span><span class="n">_feature_weights</span><span class="p">,</span> <span class="n">lagrange</span><span class="o">=</span><span class="mf">1.</span><span class="p">))</span>
        <span class="n">_unpenalized</span> <span class="o">=</span> <span class="n">_unpenalized_problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="o">**</span><span class="n">solve_args</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_unpenalized_active</span> <span class="o">=</span> <span class="n">_unpenalized</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">use_full_cov</span><span class="p">:</span>
            <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_full</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">_unpenalized</span><span class="p">)</span>
            <span class="n">n_inference</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_inference</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">n_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_full</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">H</span> <span class="o">*=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">*</span> <span class="n">n_inference</span> <span class="o">/</span> <span class="n">n_full</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_inference</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">_unpenalized</span><span class="p">)</span>

        <span class="n">H_AA</span> <span class="o">=</span> <span class="n">H</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">][:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cov_inference</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H_AA</span><span class="p">)</span></div>

<div class="viewcode-block" id="data_splitting.hypothesis_test"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.data_splitting.hypothesis_test">[docs]</a>    <span class="k">def</span> <span class="nf">hypothesis_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">variable</span><span class="p">,</span>
                        <span class="n">df</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wald test for an active variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">variable</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;expecting an active variable&#39;</span><span class="p">)</span>

        <span class="c1"># shorthand</span>
        <span class="n">j</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unpenalized_active</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cov_inference</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">df</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ndist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tdist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Z</span><span class="p">),</span> <span class="n">df</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_data_carving_deprec</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                         <span class="n">lam_frac</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span>
                         <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                         <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                         <span class="n">coverage</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                         <span class="n">ndraw</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span>
                         <span class="n">burnin</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                         <span class="n">splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">compute_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">UMPU</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a LASSO with a default choice of Lagrange parameter</span>
<span class="sd">    equal to `lam_frac` times $\sigma \cdot E(|X^T\epsilon|)$</span>
<span class="sd">    with $\epsilon$ IID N(0,1) on a proportion (`split_frac`) of</span>
<span class="sd">    the data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : np.float</span>
<span class="sd">        Response vector</span>
<span class="sd">    X : np.float</span>
<span class="sd">        Design matrix</span>
<span class="sd">    sigma : np.float</span>
<span class="sd">        Noise variance</span>
<span class="sd">    lam_frac : float (optional)</span>
<span class="sd">        Multiplier for choice of $\lambda$. Defaults to 2.</span>
<span class="sd">    coverage : float</span>
<span class="sd">        Coverage for selective intervals. Defaults to 0.95.</span>
<span class="sd">    stage_one : [np.array(np.int), None] (optional)</span>
<span class="sd">        Index of data points to be used in  first stage.</span>
<span class="sd">        If None, a randomly chosen set of entries is used based on</span>
<span class="sd">        `split_frac`.</span>
<span class="sd">    split_frac : float (optional)</span>
<span class="sd">        What proportion of the data to use in the first stage?</span>
<span class="sd">        Defaults to 0.9.</span>
<span class="sd">    ndraw : int (optional)</span>
<span class="sd">        How many draws to keep from Gibbs hit-and-run sampler.</span>
<span class="sd">        Defaults to 8000.</span>
<span class="sd">    burnin : int (optional)</span>
<span class="sd">        Defaults to 2000.</span>
<span class="sd">    splitting : bool (optional)</span>
<span class="sd">        If True, also return splitting pvalues and intervals.</span>
<span class="sd">    compute_intervals : bool (optional)</span>
<span class="sd">        Compute selective intervals?</span>
<span class="sd">    UMPU : bool (optional)</span>
<span class="sd">        Perform the UMPU test?</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    results : [(variable, pvalue, interval)</span>
<span class="sd">        Indices of active variables,</span>
<span class="sd">        selected (twosided) pvalue and selective interval.</span>
<span class="sd">        If splitting, then each entry also includes</span>
<span class="sd">        a (split_pvalue, split_interval) using stage_two</span>
<span class="sd">        for inference.</span>
<span class="sd">    stage_one : `lasso`</span>
<span class="sd">        Results of fitting LASSO to stage one data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">first_stage</span><span class="p">,</span> <span class="n">stage_one</span><span class="p">,</span> <span class="n">stage_two</span> <span class="o">=</span> <span class="n">split_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> 
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span>
                                                    <span class="n">lam_frac</span><span class="o">=</span><span class="n">lam_frac</span><span class="p">,</span>
                                                    <span class="n">split_frac</span><span class="o">=</span><span class="n">split_frac</span><span class="p">,</span>
                                                    <span class="n">stage_one</span><span class="o">=</span><span class="n">stage_one</span><span class="p">)</span>
    <span class="n">splitn</span> <span class="o">=</span> <span class="n">stage_one</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">L</span> <span class="o">=</span> <span class="n">first_stage</span>  <span class="c1"># shorthand</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">sparsity</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">splitn</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>

        <span class="c1"># JT: this is all about computing constraints for active</span>
        <span class="c1"># variables -- we already have this!</span>

        <span class="c1"># quantities related to models fit on</span>
        <span class="c1"># stage_one and full dataset</span>

        <span class="n">y1</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>
        <span class="n">X_E</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
        <span class="n">X_Ei</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_E</span><span class="p">)</span>
        <span class="n">X_E1</span> <span class="o">=</span> <span class="n">X1</span><span class="p">[:,</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
        <span class="n">X_Ei1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_E1</span><span class="p">)</span>

        <span class="n">inv_info_E</span> <span class="o">=</span> <span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_Ei</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">inv_info_E1</span> <span class="o">=</span> <span class="n">X_Ei1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_Ei1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="n">beta_E</span> <span class="o">=</span> <span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">beta_E1</span> <span class="o">=</span> <span class="n">X_Ei1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">stage_one</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span> <span class="o">&gt;</span> <span class="n">s</span><span class="p">:</span>

            <span class="n">linear_part</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">))</span>
            <span class="n">linear_part</span><span class="p">[:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active_signs</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">offset</span>
            <span class="n">con</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">linear_part</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

            <span class="c1"># specify covariance of 2s Gaussian vector</span>

            <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">))</span>
            <span class="n">cov</span><span class="p">[:</span><span class="n">s</span><span class="p">,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">inv_info_E</span>
            <span class="n">cov</span><span class="p">[</span><span class="n">s</span><span class="p">:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">inv_info_E</span>
            <span class="n">cov</span><span class="p">[:</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">inv_info_E</span>
            <span class="n">cov</span><span class="p">[</span><span class="n">s</span><span class="p">:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">inv_info_E1</span>

            <span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">cov</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span>

            <span class="c1"># for the conditional law</span>
            <span class="c1"># we will change the linear function for each coefficient</span>

            <span class="n">selector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">))</span>
            <span class="n">selector</span><span class="p">[:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
            <span class="n">conditional_linear</span> <span class="o">=</span> <span class="n">X_E</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_E</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

            <span class="c1"># a valid initial condition</span>

            <span class="n">initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">beta_E</span><span class="p">,</span> <span class="n">beta_E1</span><span class="p">])</span>
            <span class="n">OLS_func</span> <span class="o">=</span> <span class="n">selector</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">linear_part</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">))</span>
            <span class="n">linear_part</span><span class="p">[:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active_signs</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">offset</span>
            <span class="n">con</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">linear_part</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

            <span class="c1"># specify covariance of Gaussian vector</span>

            <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">))</span>
            <span class="n">cov</span><span class="p">[:</span><span class="n">s</span><span class="p">,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">inv_info_E1</span>
            <span class="n">cov</span><span class="p">[</span><span class="n">s</span><span class="p">:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cov</span><span class="p">[:</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cov</span><span class="p">[</span><span class="n">s</span><span class="p">:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">)</span>

            <span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">cov</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span>

            <span class="n">conditional_linear</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">))</span>
            <span class="n">conditional_linear</span><span class="p">[:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">inv_info_E1</span><span class="p">)</span>
            <span class="n">conditional_linear</span><span class="p">[:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">,</span> <span class="p">:][:,</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

            <span class="n">selector1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">))</span>
            <span class="n">selector1</span><span class="p">[:,</span> <span class="p">:</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
            <span class="n">selector2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">))</span>
            <span class="n">selector2</span><span class="p">[:,</span> <span class="n">s</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">)</span>

            <span class="c1"># write the OLS estimates of full model in terms of X_E1^{dagger}y_1, y2</span>

            <span class="n">OLS_func</span> <span class="o">=</span> <span class="n">inv_info_E</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">conditional_linear</span><span class="p">)</span>

            <span class="c1"># a valid initial condition</span>

            <span class="n">initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">beta_E1</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]])</span>

        <span class="n">pvalues</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">intervals</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">splitting</span><span class="p">:</span>
            <span class="n">y2</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">stage_two</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_two</span><span class="p">]</span>
            <span class="n">X_E2</span> <span class="o">=</span> <span class="n">X2</span><span class="p">[:,</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
            <span class="n">X_Ei2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_E2</span><span class="p">)</span>
            <span class="n">beta_E2</span> <span class="o">=</span> <span class="n">X_Ei2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>
            <span class="n">inv_info_E2</span> <span class="o">=</span> <span class="n">X_Ei2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_Ei2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="n">splitting_pvalues</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">splitting_intervals</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">if</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span> <span class="o">&lt;</span> <span class="n">s</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;not enough data for second stage of sample splitting&#39;</span><span class="p">)</span>

            <span class="n">split_cutoff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">ndist</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">coverage</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>

        <span class="c1"># compute p-values intervals</span>

        <span class="n">cov_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_E</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>

            <span class="n">keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
            <span class="n">keep</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">eta</span> <span class="o">=</span> <span class="n">OLS_func</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

            <span class="n">con_cp</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">con</span><span class="p">)</span>
            <span class="n">conditional_law</span> <span class="o">=</span> <span class="n">con_cp</span><span class="o">.</span><span class="n">conditional</span><span class="p">(</span><span class="n">conditional_linear</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> \
                                                 <span class="n">X_E</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="n">keep</span><span class="p">])</span>

            <span class="c1"># tilt so that samples are closer to observed values</span>
            <span class="c1"># the multiplier should be the pseudoMLE so that</span>
            <span class="c1"># the observed value is likely</span>

            <span class="n">observed</span> <span class="o">=</span> <span class="p">(</span><span class="n">initial</span> <span class="o">*</span> <span class="n">eta</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">compute_intervals</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">gibbs_test</span><span class="p">(</span><span class="n">conditional_law</span><span class="p">,</span>
                                             <span class="n">initial</span><span class="p">,</span>
                                             <span class="n">eta</span><span class="p">,</span>
                                             <span class="n">sigma_known</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">white</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                             <span class="n">ndraw</span><span class="o">=</span><span class="n">ndraw</span><span class="p">,</span>
                                             <span class="n">burnin</span><span class="o">=</span><span class="n">burnin</span><span class="p">,</span>
                                             <span class="n">how_often</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                             <span class="n">UMPU</span><span class="o">=</span><span class="n">UMPU</span><span class="p">,</span>
                                             <span class="n">tilt</span><span class="o">=</span><span class="n">conditional_law</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span>

                <span class="n">lower_lim</span><span class="p">,</span> <span class="n">upper_lim</span> <span class="o">=</span> <span class="n">family</span><span class="o">.</span><span class="n">equal_tailed_interval</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">coverage</span><span class="p">)</span>

                <span class="c1"># in the model we&#39;ve chosen, the parameter beta is associated</span>
                <span class="c1"># to the natural parameter as below</span>
                <span class="c1"># exercise: justify this!</span>

                <span class="n">lower_lim_final</span> <span class="o">=</span> <span class="n">eta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">conditional_law</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span> <span class="o">*</span> <span class="n">lower_lim</span>
                <span class="n">upper_lim_final</span> <span class="o">=</span> <span class="n">eta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">conditional_law</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span> <span class="o">*</span> <span class="n">upper_lim</span>

                <span class="n">intervals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">lower_lim_final</span><span class="p">,</span> <span class="n">upper_lim_final</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># we do not really need to tilt just for p-values</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">gibbs_test</span><span class="p">(</span><span class="n">conditional_law</span><span class="p">,</span>
                                             <span class="n">initial</span><span class="p">,</span>
                                             <span class="n">eta</span><span class="p">,</span>
                                             <span class="n">sigma_known</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">white</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                             <span class="n">ndraw</span><span class="o">=</span><span class="n">ndraw</span><span class="p">,</span>
                                             <span class="n">burnin</span><span class="o">=</span><span class="n">burnin</span><span class="p">,</span>
                                             <span class="n">how_often</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                             <span class="n">UMPU</span><span class="o">=</span><span class="n">UMPU</span><span class="p">)</span>
                <span class="n">intervals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">))</span>

            <span class="n">pval</span> <span class="o">=</span> <span class="n">family</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">observed</span><span class="p">)</span>
            <span class="n">pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">pval</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">pval</span><span class="p">)</span>

            <span class="n">pvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pval</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">splitting</span><span class="p">:</span>

                <span class="k">if</span> <span class="n">s</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">-</span> <span class="n">splitn</span><span class="p">:</span>  <span class="c1"># enough data to generically</span>
                    <span class="c1"># test hypotheses. proceed as usual</span>

                    <span class="n">split_pval</span> <span class="o">=</span> <span class="n">ndist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">beta_E2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">inv_info_E2</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">))</span>
                    <span class="n">split_pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">split_pval</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">split_pval</span><span class="p">)</span>
                    <span class="n">splitting_pvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">split_pval</span><span class="p">)</span>

                    <span class="n">splitting_interval</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta_E2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span>
                                          <span class="n">split_cutoff</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">inv_info_E2</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">,</span>
                                          <span class="n">beta_E2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span>
                                          <span class="n">split_cutoff</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">inv_info_E2</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
                    <span class="n">splitting_intervals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">splitting_interval</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">splitting_pvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
                    <span class="n">splitting_intervals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">splitting</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                       <span class="n">pvalues</span><span class="p">,</span>
                       <span class="n">intervals</span><span class="p">),</span> <span class="n">L</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                       <span class="n">pvalues</span><span class="p">,</span>
                       <span class="n">intervals</span><span class="p">,</span>
                       <span class="n">splitting_pvalues</span><span class="p">,</span>
                       <span class="n">splitting_intervals</span><span class="p">),</span> <span class="n">L</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pvalues</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">L</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="s2">&quot;twosided&quot;</span><span class="p">)[</span><span class="s1">&#39;pval&#39;</span><span class="p">]]</span>
        <span class="n">intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">L</span><span class="o">.</span><span class="n">intervals</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">],</span> <span class="n">L</span><span class="o">.</span><span class="n">intervals</span><span class="p">[</span><span class="s1">&#39;upper&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
        <span class="k">if</span> <span class="n">splitting</span><span class="p">:</span>
            <span class="n">splitting_pvalues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span>
            <span class="n">splitting_intervals</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span>
                                   <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))]</span>

            <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                       <span class="n">pvalues</span><span class="p">,</span>
                       <span class="n">intervals</span><span class="p">,</span>
                       <span class="n">splitting_pvalues</span><span class="p">,</span>
                       <span class="n">splitting_intervals</span><span class="p">),</span> <span class="n">L</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                       <span class="n">pvalues</span><span class="p">,</span>
                       <span class="n">intervals</span><span class="p">),</span> <span class="n">L</span>


<div class="viewcode-block" id="split_model"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.split_model">[docs]</a><span class="k">def</span> <span class="nf">split_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> 
                <span class="n">y</span><span class="p">,</span>
                <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">lam_frac</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                <span class="n">split_frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                <span class="n">stage_one</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a LASSO with a default choice of Lagrange parameter</span>
<span class="sd">    equal to `lam_frac` times $\sigma \cdot E(|X^T\epsilon|)$</span>
<span class="sd">    with $\epsilon$ IID N(0,1) on a proportion (`split_frac`) of</span>
<span class="sd">    the data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : np.float</span>
<span class="sd">        Response vector</span>
<span class="sd">    X : np.float</span>
<span class="sd">        Design matrix</span>
<span class="sd">    sigma : np.float</span>
<span class="sd">        Noise variance</span>
<span class="sd">    lam_frac : float (optional)</span>
<span class="sd">        Multiplier for choice of $\lambda$. Defaults to 2.</span>
<span class="sd">    split_frac : float (optional)</span>
<span class="sd">        What proportion of the data to use in the first stage?</span>
<span class="sd">        Defaults to 0.9.</span>
<span class="sd">    stage_one : [np.array(np.int), None] (optional)</span>
<span class="sd">        Index of data points to be used in  first stage.</span>
<span class="sd">        If None, a randomly chosen set of entries is used based on</span>
<span class="sd">        `split_frac`.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    first_stage : `lasso`</span>
<span class="sd">        Lasso object from stage one.</span>
<span class="sd">    stage_one : np.array(int)</span>
<span class="sd">        Indices used for stage one.</span>
<span class="sd">    stage_two : np.array(int)</span>
<span class="sd">        Indices used for stage two.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">stage_one</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">splitn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">split_frac</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">stage_one</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">splitn</span><span class="p">]</span>
        <span class="n">stage_two</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">splitn</span><span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stage_two</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stage_one</span><span class="p">]</span>
    <span class="n">y1</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">stage_one</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">stage_one</span><span class="p">]</span>

    <span class="n">first_stage</span> <span class="o">=</span> <span class="n">standard_lasso</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">lam_frac</span><span class="o">=</span><span class="n">lam_frac</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">first_stage</span><span class="p">,</span> <span class="n">stage_one</span><span class="p">,</span> <span class="n">stage_two</span></div>


<div class="viewcode-block" id="additive_noise"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.additive_noise">[docs]</a><span class="k">def</span> <span class="nf">additive_noise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                   <span class="n">y</span><span class="p">,</span>
                   <span class="n">sigma</span><span class="p">,</span>
                   <span class="n">lam_frac</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                   <span class="n">perturb_frac</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                   <span class="n">y_star</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">coverage</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                   <span class="n">ndraw</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span>
                   <span class="n">compute_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">burnin</span><span class="o">=</span><span class="mi">2000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Additive noise LASSO.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : np.float</span>
<span class="sd">        Response vector</span>
<span class="sd">    X : np.float</span>
<span class="sd">        Design matrix</span>
<span class="sd">    sigma : np.float</span>
<span class="sd">        Noise variance</span>
<span class="sd">    lam_frac : float (optional)</span>
<span class="sd">        Multiplier for choice of $\lambda$. Defaults to 2.</span>
<span class="sd">    perturb_frac : float (optional)</span>
<span class="sd">        How much noise to add? Noise added has variance</span>
<span class="sd">        proportional to existing variance.</span>
<span class="sd">    coverage : float</span>
<span class="sd">        Coverage for selective intervals. Defaults to 0.95.</span>
<span class="sd">    ndraw : int (optional)</span>
<span class="sd">        How many draws to keep from Gibbs hit-and-run sampler.</span>
<span class="sd">        Defaults to 8000.</span>
<span class="sd">    burnin : int (optional)</span>
<span class="sd">        Defaults to 2000.</span>
<span class="sd">    compute_intervals : bool (optional)</span>
<span class="sd">        Compute selective intervals?</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    results : [(variable, pvalue, interval)</span>
<span class="sd">        Indices of active variables,</span>
<span class="sd">        selected (twosided) pvalue and selective interval.</span>
<span class="sd">        If splitting, then each entry also includes</span>
<span class="sd">        a (split_pvalue, split_interval) using stage_two</span>
<span class="sd">        for inference.</span>
<span class="sd">    randomized_lasso : `lasso`</span>
<span class="sd">        Results of fitting LASSO to randomized data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Add some noise to y and fit the LASSO at a fixed lambda</span>

    <span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">perturb_frac</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span>
    <span class="n">sigma_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">lam_frac</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">5000</span><span class="p">))))</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">*</span> <span class="n">sigma_star</span>
    <span class="n">y_star</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">gamma</span>

    <span class="n">randomized_lasso</span> <span class="o">=</span> <span class="n">L</span> <span class="o">=</span> <span class="n">standard_lasso</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_star</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_star</span><span class="p">,</span> <span class="n">lam_frac</span><span class="o">=</span><span class="n">lam_frac</span><span class="p">)</span>
    <span class="n">L</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

    <span class="c1"># Form the constraint matrix on (y,y^*)</span>
    <span class="n">X_E</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
    <span class="n">X_Ei</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_E</span><span class="p">)</span>
    <span class="n">Cov_E</span> <span class="o">=</span> <span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_Ei</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">W_E</span> <span class="o">=</span> <span class="n">Cov_E</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active_signs</span><span class="p">)</span>

    <span class="n">pvalues</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">intervals</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">beta_E</span> <span class="o">=</span> <span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># compute each pvalue</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_E</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">s_obs</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">s_obs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="n">keep</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># form the 2s Gaussian vector we will condition on</span>

        <span class="n">X_minus_j</span> <span class="o">=</span> <span class="n">X_E</span><span class="p">[:,</span> <span class="n">keep</span><span class="p">]</span>
        <span class="n">P_minus_j</span> <span class="o">=</span> <span class="n">X_minus_j</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_minus_j</span><span class="p">))</span>
        <span class="n">R_minus_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="n">P_minus_j</span>

        <span class="n">theta_E</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">active_signs</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P_minus_j</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">-</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">W_E</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Cov_E</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
        <span class="n">kappa</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">scale</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">alpha_E</span> <span class="o">=</span> <span class="n">kappa</span> <span class="o">*</span> <span class="n">L</span><span class="o">.</span><span class="n">active_signs</span> <span class="o">*</span> <span class="n">Cov_E</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="o">-</span><span class="n">alpha_E</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">s_obs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">s_obs</span><span class="p">)])</span>
        <span class="n">con</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">theta_E</span><span class="p">)</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">s_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">s_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">Cov_E</span> <span class="o">*</span> <span class="n">gamma</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active_signs</span><span class="p">,</span> <span class="n">L</span><span class="o">.</span><span class="n">active_signs</span><span class="p">)</span>
        <span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">cov</span>
        <span class="n">initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">s_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">initial</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta_E</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">initial</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="n">X_Ei</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_star</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">L</span><span class="o">.</span><span class="n">active_signs</span>
        <span class="n">eta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">s_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">eta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

        <span class="n">observed</span> <span class="o">=</span> <span class="p">(</span><span class="n">initial</span> <span class="o">*</span> <span class="n">eta</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">compute_intervals</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">gibbs_test</span><span class="p">(</span><span class="n">con</span><span class="p">,</span>
                                         <span class="n">initial</span><span class="p">,</span>
                                         <span class="n">eta</span><span class="p">,</span>
                                         <span class="n">UMPU</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">sigma_known</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">ndraw</span><span class="o">=</span><span class="n">ndraw</span><span class="p">,</span>
                                         <span class="n">burnin</span><span class="o">=</span><span class="n">burnin</span><span class="p">,</span>
                                         <span class="n">how_often</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                         <span class="n">tilt</span><span class="o">=</span><span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span>

            <span class="n">lower_lim</span><span class="p">,</span> <span class="n">upper_lim</span> <span class="o">=</span> <span class="n">family</span><span class="o">.</span><span class="n">equal_tailed_interval</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">coverage</span><span class="p">)</span>

            <span class="c1"># in the model we&#39;ve chosen, the parameter beta is associated</span>
            <span class="c1"># to the natural parameter as below</span>
            <span class="c1"># exercise: justify this!</span>

            <span class="n">lower_lim_final</span> <span class="o">=</span> <span class="n">eta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span> <span class="o">*</span> <span class="n">lower_lim</span>
            <span class="n">upper_lim_final</span> <span class="o">=</span> <span class="n">eta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span> <span class="o">*</span> <span class="n">upper_lim</span>

            <span class="n">intervals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">lower_lim_final</span><span class="p">,</span> <span class="n">upper_lim_final</span><span class="p">))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">gibbs_test</span><span class="p">(</span><span class="n">con</span><span class="p">,</span>
                                         <span class="n">initial</span><span class="p">,</span>
                                         <span class="n">eta</span><span class="p">,</span>
                                         <span class="n">UMPU</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">sigma_known</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">ndraw</span><span class="o">=</span><span class="n">ndraw</span><span class="p">,</span>
                                         <span class="n">burnin</span><span class="o">=</span><span class="n">burnin</span><span class="p">,</span>
                                         <span class="n">how_often</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                         <span class="n">tilt</span><span class="o">=</span><span class="n">con</span><span class="o">.</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span>

            <span class="n">intervals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">))</span>

        <span class="n">pval</span> <span class="o">=</span> <span class="n">family</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">observed</span><span class="p">)</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">pval</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">pval</span><span class="p">)</span>
        <span class="n">pvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pval</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
               <span class="n">pvalues</span><span class="p">,</span>
               <span class="n">intervals</span><span class="p">),</span> <span class="n">randomized_lasso</span></div>


<span class="c1">## Liu, Markovic and Tibshirani method based on full model</span>
<span class="c1">## conditioning only on the event j \in E for each active j</span>

<span class="c1"># Liu, Markovic, Tibs selection</span>

<span class="k">def</span> <span class="nf">_solve_restricted_problem</span><span class="p">(</span><span class="n">Qbeta_bar</span><span class="p">,</span> <span class="n">Xinfo</span><span class="p">,</span> <span class="n">lagrange</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">wide</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">min_its</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.e-12</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">Qbeta_bar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">wide</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">Xinfo</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">squared_error</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">W</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">Xinfo</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">quadratic_loss</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="o">=</span><span class="n">Q</span><span class="p">)</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">quadratic</span> <span class="o">=</span> <span class="n">identity_quadratic</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>
                                        <span class="mi">0</span><span class="p">,</span>
                                        <span class="o">-</span><span class="n">Qbeta_bar</span><span class="p">,</span>
                                        <span class="mi">0</span><span class="p">)</span>

    <span class="n">lagrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">lagrange</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lagrange</span><span class="o">.</span><span class="n">shape</span> <span class="ow">in</span> <span class="p">[(),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)]:</span>
        <span class="n">lagrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">lagrange</span>
    <span class="n">pen</span> <span class="o">=</span> <span class="n">weighted_l1norm</span><span class="p">(</span><span class="n">lagrange</span><span class="p">,</span> <span class="n">lagrange</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">problem</span> <span class="o">=</span> <span class="n">simple_problem</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">pen</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">initial</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">problem</span><span class="o">.</span><span class="n">coefs</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">initial</span>
    <span class="n">soln</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">min_its</span><span class="o">=</span><span class="n">min_its</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">soln</span>


<span class="k">def</span> <span class="nf">_truncation_interval</span><span class="p">(</span><span class="n">Qbeta_bar</span><span class="p">,</span> 
                         <span class="n">Xinfo</span><span class="p">,</span> 
                         <span class="n">Qi_jj</span><span class="p">,</span> 
                         <span class="n">j</span><span class="p">,</span> 
                         <span class="n">beta_barj</span><span class="p">,</span> 
                         <span class="n">lagrange</span><span class="p">,</span> 
                         <span class="n">wide</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">lagrange</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">lagrange_cp</span> <span class="o">=</span> <span class="n">lagrange</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">lagrange_cp</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="c1"># TODO: use initial solution for speed</span>
    <span class="n">restricted_soln</span> <span class="o">=</span> <span class="n">_solve_restricted_problem</span><span class="p">(</span><span class="n">Qbeta_bar</span><span class="p">,</span> 
                                                <span class="n">Xinfo</span><span class="p">,</span> 
                                                <span class="n">lagrange_cp</span><span class="p">,</span> 
                                                <span class="n">wide</span><span class="o">=</span><span class="n">wide</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">Qbeta_bar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Ij</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">Ij</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
    <span class="n">nuisance</span> <span class="o">=</span> <span class="n">Qbeta_bar</span> <span class="o">-</span> <span class="n">Ij</span> <span class="o">/</span> <span class="n">Qi_jj</span> <span class="o">*</span> <span class="n">beta_barj</span>

    <span class="k">if</span> <span class="n">wide</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">Xinfo</span>
        <span class="n">Qj</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">Xinfo</span>
        <span class="n">Qj</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="n">center</span> <span class="o">=</span> <span class="n">nuisance</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">Qj</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">restricted_soln</span><span class="p">)</span>
    <span class="n">upper</span> <span class="o">=</span> <span class="p">(</span><span class="n">lagrange</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">*</span> <span class="n">Qi_jj</span>
    <span class="n">lower</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">lagrange</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span> <span class="o">*</span> <span class="n">Qi_jj</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">beta_barj</span> <span class="o">&lt;</span> <span class="n">lower</span> <span class="ow">or</span> <span class="n">beta_barj</span> <span class="o">&gt;</span> <span class="n">upper</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;implied KKT constraint not satisfied&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span>

<div class="viewcode-block" id="ROSI"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI">[docs]</a><span class="k">class</span> <span class="nc">ROSI</span><span class="p">(</span><span class="n">lasso</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for the LASSO for post-selection inference.</span>
<span class="sd">    The problem solved is</span>
<span class="sd">    .. math::</span>
<span class="sd">        \text{minimize}_{\beta} \frac{1}{2n} \|y-X\beta\|^2_2 +</span>
<span class="sd">            \lambda \|\beta\|_1</span>
<span class="sd">    where $\lambda$ is `lam`.</span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In solving the debiasing problem to approximate the inverse</span>
<span class="sd">    of (X^TWX) in a GLM, this class makes the implicit assumption</span>
<span class="sd">    that the scaling of X is such that diag(X^TWX) is O(n)</span>
<span class="sd">    with n=X.shape[0]. That is, X&#39;s are similar to IID samples</span>
<span class="sd">    from a population that does not depend on n.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ROSI.__init__"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">loglike</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">approximate_inverse</span><span class="o">=</span><span class="s1">&#39;BN&#39;</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new post-selection for the LASSO problem</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loglike : `regreg.smooth.glm.glm`</span>
<span class="sd">            A (negative) log-likelihood as implemented in `regreg`.</span>
<span class="sd">        feature_weights : np.ndarray</span>
<span class="sd">            Feature weights for L-1 penalty. If a float,</span>
<span class="sd">            it is brodcast to all features.</span>
<span class="sd">        approximate_inverse : str (optional)</span>
<span class="sd">             One of &quot;JM&quot; (Javanmard, Montanari) or &quot;BN&quot; (Boot, Niedderling) or None.</span>
<span class="sd">             A form of approximate inverse when p is close to (or larger) than n.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span> <span class="o">=</span> <span class="n">loglike</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
            <span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">loglike</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">feature_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">approximate_inverse</span> <span class="o">=</span> <span class="n">approximate_inverse</span></div>

<div class="viewcode-block" id="ROSI.fit"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">lasso_solution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1.e-12</span><span class="p">,</span> <span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">},</span>
            <span class="n">debiasing_args</span><span class="o">=</span><span class="p">{}):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the lasso using `regreg`.</span>
<span class="sd">        This sets the attributes `soln`, `onestep` and</span>
<span class="sd">        forms the constraints necessary for post-selection inference</span>
<span class="sd">        by calling `form_constraints()`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lasso_solution : optional</span>
<span class="sd">             If not None, this is taken to be the solution</span>
<span class="sd">             of the optimization problem. No checks</span>
<span class="sd">             are done, though the implied affine</span>
<span class="sd">             constraints will generally not be satisfied.</span>
<span class="sd">        solve_args : keyword args</span>
<span class="sd">             Passed to `regreg.problems.simple_problem.solve`.</span>
<span class="sd">        debiasing_args : dict</span>
<span class="sd">             Arguments passed to `.debiased_lasso.debiasing_matrix`</span>
<span class="sd">             or `.debiased_lasso.pseudoinverse_debiasing_matrix` depending</span>
<span class="sd">             on `self.approximate_inverse`.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        soln : np.float</span>
<span class="sd">             Solution to lasso.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If `self` already has an attribute `lasso_solution`</span>
<span class="sd">        this will be taken to be the solution and</span>
<span class="sd">        no optimization problem will be solved. Supplying</span>
<span class="sd">        the optional argument `lasso_solution` will</span>
<span class="sd">        overwrite `self`&#39;s `lasso_solution`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_penalty</span> <span class="o">=</span> <span class="n">weighted_l1norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">,</span> <span class="n">lagrange</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lasso_solution</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lasso_solution&quot;</span><span class="p">):</span>
            <span class="n">problem</span> <span class="o">=</span> <span class="n">simple_problem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_penalty</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="o">**</span><span class="n">solve_args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">lasso_solution</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">lasso_solution</span>

        <span class="n">lasso_solution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span>  <span class="c1"># shorthand after setting it correctly above</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">lasso_solution</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">active</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">lasso_solution</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span> <span class="o">=</span> <span class="n">lasso_solution</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_active_soln</span> <span class="o">=</span> <span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>

            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># presuming GLM here</span>
            <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">saturated_loss</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">))</span>

            <span class="c1"># Needed for finding truncation intervals</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_Qbeta_bar</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">))</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">smooth_objective</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">,</span> <span class="s1">&#39;grad&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_W</span> <span class="o">=</span> <span class="n">W</span>

            <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="n">p</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">approximate_inverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

                <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">)</span>
                <span class="n">E</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span>
                <span class="n">Qi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_QiE</span> <span class="o">=</span> <span class="n">Qi</span><span class="p">[</span><span class="n">E</span><span class="p">][:,</span> <span class="n">E</span><span class="p">]</span>
                <span class="n">_beta_bar</span> <span class="o">=</span> <span class="n">Qi</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_Qbeta_bar</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_beta_barE</span> <span class="o">=</span> <span class="n">_beta_bar</span><span class="p">[</span><span class="n">E</span><span class="p">]</span>
                <span class="n">one_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta_barE</span>

                <span class="c1"># Pearson&#39;s X^2 to estimate sigma</span>

                <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">saturated_loss</span><span class="o">.</span><span class="n">mean_function</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">_beta_bar</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_pearson_sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_W</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">approximate_inverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;n is less than or equal to p, an approximate inverse is needed.&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>

                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">data</span>

                <span class="c1"># target is one-step estimator</span>

                <span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">smooth_objective</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">,</span> <span class="s1">&#39;grad&#39;</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">approximate_inverse</span> <span class="o">==</span> <span class="s1">&#39;JM&#39;</span><span class="p">:</span>
                    <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_M</span> <span class="o">=</span> <span class="n">debiasing_matrix</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">W</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">],</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                                                   <span class="o">**</span><span class="n">debiasing_args</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
                    <span class="c1"># the n is to make sure we get rows of the inverse</span>
                    <span class="c1"># of (X^TWX) instead of (X^TWX/n).</span>

                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">approximate_inverse</span> <span class="o">==</span> <span class="s1">&#39;BN&#39;</span><span class="p">:</span>
                    <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_M</span> <span class="o">=</span> <span class="n">pseudoinverse_debiasing_matrix</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">W</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">],</span>
                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                                                                 <span class="o">**</span><span class="n">debiasing_args</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;approximate inverse should be one of [&quot;JM&quot;, &quot;BN&quot;]&#39;</span><span class="p">)</span>

                <span class="n">Qinv_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">M</span><span class="p">)</span> 
                <span class="n">observed_target</span> <span class="o">=</span> <span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span> <span class="o">-</span> <span class="n">Qinv_hat</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
                <span class="n">M1</span> <span class="o">=</span> <span class="n">Qinv_hat</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_QiE</span> <span class="o">=</span> <span class="p">(</span><span class="n">M1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_W</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">Xfeat</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>
                <span class="n">Qrelax</span> <span class="o">=</span> <span class="n">Xfeat</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_W</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">Xfeat</span><span class="p">)</span>
                <span class="n">relaxed_soln</span> <span class="o">=</span> <span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Qrelax</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_beta_barE</span> <span class="o">=</span> <span class="n">observed_target</span>

                <span class="c1"># relaxed Pearson&#39;s X^2 to estimate sigma</span>
                <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">saturated_loss</span><span class="o">.</span><span class="n">mean_function</span><span class="p">(</span><span class="n">Xfeat</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">relaxed_soln</span><span class="p">))</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">_pearson_sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_W</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">lasso_solution</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span></div>

<div class="viewcode-block" id="ROSI.summary"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI.summary">[docs]</a>    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                <span class="n">compute_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">dispersion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">truth</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Summary table for inference adjusted for selection.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        level : float</span>
<span class="sd">            Form level*100% selective confidence intervals.</span>

<span class="sd">        compute_intervals : bool</span>
<span class="sd">            Should we compute confidence intervals?</span>

<span class="sd">        dispersion : float</span>
<span class="sd">            Estimate of dispersion. Defaults to a Pearson&#39;s X^2 estimate in the relaxed model.</span>

<span class="sd">        truth : np.array</span>
<span class="sd">            True values of each beta for selected variables. If not None, a column &#39;pval&#39; are p-values</span>
<span class="sd">            computed under these corresponding null hypotheses.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pval_summary : np.recarray</span>
<span class="sd">            Array with one entry per active variable.</span>
<span class="sd">            Columns are &#39;variable&#39;, &#39;pval&#39;, &#39;lasso&#39;, &#39;onestep&#39;, &#39;lower_trunc&#39;, &#39;upper_trunc&#39;, &#39;sd&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike</span><span class="o">.</span><span class="n">data</span>
            <span class="n">active_set</span><span class="p">,</span> <span class="n">QiE</span><span class="p">,</span> <span class="n">beta_barE</span><span class="p">,</span> <span class="n">Qbeta_bar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_QiE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta_barE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Qbeta_bar</span>
            <span class="n">W</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pearson_sigma</span>
            <span class="k">if</span> <span class="n">dispersion</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sqrt_dispersion</span> <span class="o">=</span> <span class="n">sigma</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sqrt_dispersion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dispersion</span><span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># note that QiE is the dispersion free covariance</span>
            <span class="c1"># matrix!</span>
            <span class="c1"># dispersion comes into truncated Gaussian below</span>

            <span class="k">if</span> <span class="n">truth</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">truth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)):</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">_truncation_interval</span><span class="p">(</span><span class="n">Qbeta_bar</span><span class="p">,</span> 
                                                    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> 
                                                    <span class="n">QiE</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> 
                                                    <span class="n">idx</span><span class="p">,</span> 
                                                    <span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">,</span> 
                                                    <span class="n">wide</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="n">sd</span> <span class="o">=</span> <span class="n">sqrt_dispersion</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">QiE</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">tg</span> <span class="o">=</span> <span class="n">TG</span><span class="p">([(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)],</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">truth</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">pvalue</span> <span class="o">=</span> <span class="n">tg</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">pvalue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">pvalue</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">pvalue</span><span class="p">))</span>

                <span class="k">if</span> <span class="n">compute_intervals</span><span class="p">:</span>
                    <span class="n">l</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">tg</span><span class="o">.</span><span class="n">equal_tailed_interval</span><span class="p">(</span><span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">level</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">l</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">sd</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">))</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                              <span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">([(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;pval&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;lasso&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;onestep&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;sd&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;lower_confidence&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;upper_confidence&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;lower_truncation&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;upper_truncation&#39;</span><span class="p">],</span>
                                                                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)]))</span>
            <span class="n">df</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">df</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">soln</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Solution to the lasso problem, set by `fit` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lasso_solution&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span>

<div class="viewcode-block" id="ROSI.gaussian"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI.gaussian">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">gaussian</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">Y</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">approximate_inverse</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Squared-error LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \frac{1}{2} \|Y-X\beta\|^2_2 + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\lambda$ is `feature_weights`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        Y : ndarray</span>
<span class="sd">            Shape (n,) -- the response.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        sigma : float (optional)</span>
<span class="sd">            Noise variance. Set to 1 if `covariance_estimator` is not None.</span>
<span class="sd">            This scales the loglikelihood by `sigma**(-2)`.</span>
<span class="sd">        covariance_estimator : callable (optional)</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of some of the</span>
<span class="sd">        rows and columns of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">covariance_estimator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">approximate_inverse</span><span class="o">=</span><span class="n">approximate_inverse</span><span class="p">)</span></div>

<div class="viewcode-block" id="ROSI.logistic"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI.logistic">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">logistic</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">successes</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">,</span>
                 <span class="n">trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">approximate_inverse</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Logistic LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \ell(X\beta) + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\ell$ is the negative of the logistic</span>
<span class="sd">        log-likelihood (half the logistic deviance)</span>
<span class="sd">        and $\lambda$ is `feature_weights`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        successes : ndarray</span>
<span class="sd">            Shape (n,) -- response vector. An integer number of successes.</span>
<span class="sd">            For data that is proportions, multiply the proportions</span>
<span class="sd">            by the number of trials first.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        trials : ndarray (optional)</span>
<span class="sd">            Number of trials per response, defaults to</span>
<span class="sd">            ones the same shape as Y.</span>
<span class="sd">        covariance_estimator : optional</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">successes</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="n">trials</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span>
                     <span class="n">approximate_inverse</span><span class="o">=</span><span class="n">approximate_inverse</span><span class="p">)</span></div>

<div class="viewcode-block" id="ROSI.poisson"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI.poisson">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">poisson</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">counts</span><span class="p">,</span>
                <span class="n">feature_weights</span><span class="p">,</span>
                <span class="n">covariance_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">quadratic</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">approximate_inverse</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Poisson log-linear LASSO with feature weights.</span>
<span class="sd">        Objective function is</span>
<span class="sd">        $$</span>
<span class="sd">        \beta \mapsto \ell^{\text{Poisson}}(\beta) + \sum_{i=1}^p \lambda_i |\beta_i|</span>
<span class="sd">        $$</span>
<span class="sd">        where $\ell^{\text{Poisson}}$ is the negative</span>
<span class="sd">        of the log of the Poisson likelihood (half the deviance)</span>
<span class="sd">        and $\lambda$ is `feature_weights`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray</span>
<span class="sd">            Shape (n,p) -- the design matrix.</span>
<span class="sd">        counts : ndarray</span>
<span class="sd">            Shape (n,) -- the response.</span>
<span class="sd">        feature_weights: [float, sequence]</span>
<span class="sd">            Penalty weights. An intercept, or other unpenalized</span>
<span class="sd">            features are handled by setting those entries of</span>
<span class="sd">            `feature_weights` to 0. If `feature_weights` is</span>
<span class="sd">            a float, then all parameters are penalized equally.</span>
<span class="sd">        covariance_estimator : optional</span>
<span class="sd">            If None, use the parameteric</span>
<span class="sd">            covariance estimate of the selected model.</span>
<span class="sd">        quadratic : `regreg.identity_quadratic.identity_quadratic` (optional)</span>
<span class="sd">            An optional quadratic term to be added to the objective.</span>
<span class="sd">            Can also be a linear term by setting quadratic</span>
<span class="sd">            coefficient to 0.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        L : `selection.algorithms.lasso.lasso`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If not None, `covariance_estimator` should</span>
<span class="sd">        take arguments (beta, active, inactive)</span>
<span class="sd">        and return an estimate of the covariance of</span>
<span class="sd">        $(\bar{\beta}_E, \nabla \ell(\bar{\beta}_E)_{-E})$,</span>
<span class="sd">        the unpenalized estimator and the inactive</span>
<span class="sd">        coordinates of the gradient of the likelihood at</span>
<span class="sd">        the unpenalized estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loglike</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">quadratic</span><span class="o">=</span><span class="n">quadratic</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">klass</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">feature_weights</span><span class="p">,</span>
                     <span class="n">approximate_inverse</span><span class="o">=</span><span class="n">approximate_inverse</span><span class="p">)</span></div></div>

<div class="viewcode-block" id="ROSI_modelQ"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI_modelQ">[docs]</a><span class="k">class</span> <span class="nc">ROSI_modelQ</span><span class="p">(</span><span class="n">lasso</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for the LASSO for post-selection inference</span>
<span class="sd">    in which</span>
<span class="sd">    The problem solved is</span>
<span class="sd">    .. math::</span>
<span class="sd">        \text{minimize}_{\beta} -(X\beta)^Ty + \frac{1}{2} \beta^TQ\beta +</span>
<span class="sd">            \sum_i \lambda_i |\beta_i|</span>
<span class="sd">    where $\lambda$ is `feature_weights`.</span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In solving the debiasing problem to approximate the inverse</span>
<span class="sd">    of (X^TWX) in a GLM, this class makes the implicit assumption</span>
<span class="sd">    that the scaling of X is such that diag(X^TWX) is O(n)</span>
<span class="sd">    with n=X.shape[0]. That is, X&#39;s are similar to IID samples</span>
<span class="sd">    from a population that does not depend on n.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ROSI_modelQ.__init__"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI_modelQ.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">Q</span><span class="p">,</span>  <span class="c1"># population or semi-supervised version of X.T.dot(X)</span>
                 <span class="n">X</span><span class="p">,</span>
                 <span class="n">y</span><span class="p">,</span>
                 <span class="n">feature_weights</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new post-selection for the LASSO problem</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Q : np.ndarray((p,p))</span>
<span class="sd">        X : np.ndarray((n, p))</span>
<span class="sd">        y : np.ndarray(n)</span>
<span class="sd">        feature_weights : np.ndarray</span>
<span class="sd">            Feature weights for L-1 penalty. If a float,</span>
<span class="sd">            it is brodcast to all features.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="o">=</span> <span class="n">Q</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">quadratic_loss</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="o">=</span><span class="n">Q</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_linear_term</span> <span class="o">=</span> <span class="n">identity_quadratic</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
            <span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">feature_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="ROSI_modelQ.fit"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI_modelQ.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">solve_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="mf">1.e-12</span><span class="p">,</span> <span class="s1">&#39;min_its&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">},</span>
            <span class="n">debiasing_args</span><span class="o">=</span><span class="p">{}):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the lasso using `regreg`.</span>
<span class="sd">        This sets the attributes `soln`, `onestep` and</span>
<span class="sd">        forms the constraints necessary for post-selection inference</span>
<span class="sd">        by calling `form_constraints()`.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lasso_solution : optional</span>
<span class="sd">             If not None, this is taken to be the solution</span>
<span class="sd">             of the optimization problem. No checks</span>
<span class="sd">             are done, though the implied affine</span>
<span class="sd">             constraints will generally not be satisfied.</span>
<span class="sd">        solve_args : keyword args</span>
<span class="sd">             Passed to `regreg.problems.simple_problem.solve`.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        soln : np.float</span>
<span class="sd">             Solution to lasso.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If `self` already has an attribute `lasso_solution`</span>
<span class="sd">        this will be taken to be the solution and</span>
<span class="sd">        no optimization problem will be solved. Supplying</span>
<span class="sd">        the optional argument `lasso_solution` will</span>
<span class="sd">        overwrite `self`&#39;s `lasso_solution`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_penalty</span> <span class="o">=</span> <span class="n">weighted_l1norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">,</span> <span class="n">lagrange</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
        <span class="n">problem</span> <span class="o">=</span> <span class="n">simple_problem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_penalty</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_linear_term</span><span class="p">,</span> <span class="o">**</span><span class="n">solve_args</span><span class="p">)</span>

        <span class="n">lasso_solution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span>  <span class="c1"># shorthand after setting it correctly above</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">lasso_solution</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">active</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">lasso_solution</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span> <span class="o">=</span> <span class="n">lasso_solution</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active_signs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_active_soln</span> <span class="o">=</span> <span class="n">lasso_solution</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">]</span>

            <span class="c1"># Needed for finding truncation intervals</span>

            <span class="n">G</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">smooth_objective</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">,</span> <span class="s1">&#39;grad&#39;</span><span class="p">)</span> <span class="o">+</span> 
                 <span class="bp">self</span><span class="o">.</span><span class="n">_linear_term</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">,</span> <span class="s1">&#39;grad&#39;</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_Qbeta_bar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">lasso_solution</span><span class="p">)</span> <span class="o">-</span> <span class="n">G</span>

            <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span>
            <span class="n">E</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span>
            <span class="n">QiE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)[</span><span class="n">E</span><span class="p">]</span>  <span class="c1"># maybe we want to use a debised estimate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_QiE</span> <span class="o">=</span> <span class="n">QiE</span><span class="p">[:,</span> <span class="n">E</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_beta_barE</span> <span class="o">=</span> <span class="n">QiE</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_Qbeta_bar</span><span class="p">)</span>

            <span class="c1"># Pearson&#39;s X^2 to estimate sigma from relaxed estimator</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>
            <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">relaxed_beta_barE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">E</span><span class="p">][:,</span> <span class="n">E</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">E</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pearson_sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">y</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">E</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">relaxed_beta_barE</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">active</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inactive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">lasso_solution</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span></div>

<div class="viewcode-block" id="ROSI_modelQ.summary"><a class="viewcode-back" href="../../../api/generated/selectinf.algorithms.lasso.html#selectinf.algorithms.lasso.ROSI_modelQ.summary">[docs]</a>    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                <span class="n">compute_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">dispersion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Summary table for inference adjusted for selection.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        level : float</span>
<span class="sd">            Form level*100% selective confidence intervals.</span>
<span class="sd">        compute_intervals : bool</span>
<span class="sd">            Should we compute confidence intervals?</span>
<span class="sd">        dispersion : float</span>
<span class="sd">            Estimate of dispersion. Defaults to a Pearson&#39;s X^2 estimate in the relaxed model.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pval_summary : np.recarray</span>
<span class="sd">            Array with one entry per active variable.</span>
<span class="sd">            Columns are &#39;variable&#39;, &#39;pval&#39;, &#39;lasso&#39;, &#39;onestep&#39;, &#39;lower_trunc&#39;, &#39;upper_trunc&#39;, &#39;sd&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pearson_sigma</span>
            <span class="k">if</span> <span class="n">dispersion</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sqrt_dispersion</span> <span class="o">=</span> <span class="n">sigma</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sqrt_dispersion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dispersion</span><span class="p">)</span>
            <span class="n">active_set</span><span class="p">,</span> <span class="n">QiE</span><span class="p">,</span> <span class="n">beta_barE</span><span class="p">,</span> <span class="n">Qbeta_bar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_QiE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta_barE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Qbeta_bar</span>

            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">)):</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">_truncation_interval</span><span class="p">(</span><span class="n">Qbeta_bar</span><span class="p">,</span> 
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">,</span> 
                                                    <span class="n">QiE</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> 
                                                    <span class="n">idx</span><span class="p">,</span> 
                                                    <span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">],</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">feature_weights</span><span class="p">,</span> 
                                                    <span class="n">wide</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">sd</span> <span class="o">=</span> <span class="n">sqrt_dispersion</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">QiE</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">tg</span> <span class="o">=</span> <span class="n">TG</span><span class="p">([(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)],</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
                <span class="n">pvalue</span> <span class="o">=</span> <span class="n">tg</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">pvalue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">pvalue</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">pvalue</span><span class="p">))</span>

                <span class="k">if</span> <span class="n">compute_intervals</span><span class="p">:</span>
                    <span class="n">l</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">tg</span><span class="o">.</span><span class="n">equal_tailed_interval</span><span class="p">(</span><span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">level</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">l</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lasso_solution</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">beta_barE</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">sd</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">))</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">active</span><span class="p">,</span>
                              <span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">([(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;pval&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;lasso&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;onestep&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;sd&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;lower_confidence&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;upper_confidence&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;lower_truncation&#39;</span><span class="p">,</span>
                                                                 <span class="s1">&#39;upper_truncation&#39;</span><span class="p">],</span>
                                                                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)]))</span>
            <span class="n">df</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;variable&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">df</span></div></div>

</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright J. Taylor and others
      <span class="lastupdated">
        Last updated on Sep 25, 2019.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>