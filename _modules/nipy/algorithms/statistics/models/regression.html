

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Selection &mdash; Selection Documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html">
          

          
            
            <img src="../../../../../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../documentation.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../algorithms/index.html">Non-randomized algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../randomized/index.html">Randomized algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../learning/index.html">Learning selection</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">selection</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
      <li>Selection</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nipy.algorithms.statistics.models.regression</h1><div class="highlight"><pre>
<span></span><span class="c1"># emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode: nil -*-</span>
<span class="c1"># vi: set ft=python sts=4 ts=4 sw=4 et:</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module implements some standard regression models: OLS and WLS</span>
<span class="sd">models, as well as an AR(p) regression model.</span>

<span class="sd">Models are specified with a design matrix and are fit using their</span>
<span class="sd">&#39;fit&#39; method.</span>

<span class="sd">Subclasses that have more complicated covariance matrices</span>
<span class="sd">should write over the &#39;whiten&#39; method as the fit method</span>
<span class="sd">prewhitens the response by calling &#39;whiten&#39;.</span>

<span class="sd">General reference for regression models:</span>

<span class="sd">&#39;Introduction to Linear Regression Analysis&#39;, Douglas C. Montgomery,</span>
<span class="sd">    Elizabeth A. Peck, G. Geoffrey Vining. Wiley, 2006.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>

<span class="n">__docformat__</span> <span class="o">=</span> <span class="s1">&#39;restructuredtext en&#39;</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">npl</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">spl</span>

<span class="kn">from</span> <span class="nn">nibabel.onetime</span> <span class="k">import</span> <span class="n">setattr_on_read</span>

<span class="kn">from</span> <span class="nn">nipy.algorithms.utils.matrices</span> <span class="k">import</span> <span class="n">matrix_rank</span><span class="p">,</span> <span class="n">pos_recipr</span>

<span class="kn">from</span> <span class="nn">.model</span> <span class="k">import</span> <span class="n">LikelihoodModel</span><span class="p">,</span> <span class="n">LikelihoodModelResults</span>

<span class="c1"># Legacy repr printing from numpy.</span>
<span class="kn">from</span> <span class="nn">nipy.testing</span> <span class="k">import</span> <span class="n">legacy_printing</span> <span class="k">as</span> <span class="n">setup_module</span>  <span class="c1"># noqa</span>


<div class="viewcode-block" id="OLSModel"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel">[docs]</a><span class="k">class</span> <span class="nc">OLSModel</span><span class="p">(</span><span class="n">LikelihoodModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A simple ordinary least squares model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    design : array-like</span>
<span class="sd">        This is your design matrix.  Data are assumed to be column ordered with</span>
<span class="sd">        observations in rows.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    model.__init___(design)</span>
<span class="sd">    model.logL(b=self.beta, Y)</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    design : ndarray</span>
<span class="sd">        This is the design, or X, matrix.</span>
<span class="sd">    wdesign : ndarray</span>
<span class="sd">        This is the whitened design matrix.  `design` == `wdesign` by default</span>
<span class="sd">        for the OLSModel, though models that inherit from the OLSModel will</span>
<span class="sd">        whiten the design.</span>
<span class="sd">    calc_beta : ndarray</span>
<span class="sd">        This is the Moore-Penrose pseudoinverse of the whitened design matrix.</span>
<span class="sd">    normalized_cov_beta : ndarray</span>
<span class="sd">        ``np.dot(calc_beta, calc_beta.T)``</span>
<span class="sd">    df_resid : scalar</span>
<span class="sd">        Degrees of freedom of the residuals.  Number of observations less the</span>
<span class="sd">        rank of the design.</span>
<span class="sd">    df_model : scalar</span>
<span class="sd">        Degrees of freedome of the model.  The rank of the design.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from nipy.algorithms.statistics.api import Term, Formula</span>
<span class="sd">    &gt;&gt;&gt; data = np.rec.fromarrays(([1,3,4,5,2,3,4], range(1,8)),</span>
<span class="sd">    ...                          names=(&#39;Y&#39;, &#39;X&#39;))</span>
<span class="sd">    &gt;&gt;&gt; f = Formula([Term(&quot;X&quot;), 1])</span>
<span class="sd">    &gt;&gt;&gt; dmtx = f.design(data, return_float=True)</span>
<span class="sd">    &gt;&gt;&gt; model = OLSModel(dmtx)</span>
<span class="sd">    &gt;&gt;&gt; results = model.fit(data[&#39;Y&#39;])</span>
<span class="sd">    &gt;&gt;&gt; results.theta</span>
<span class="sd">    array([ 0.25      ,  2.14285714])</span>
<span class="sd">    &gt;&gt;&gt; results.t()</span>
<span class="sd">    array([ 0.98019606,  1.87867287])</span>
<span class="sd">    &gt;&gt;&gt; print(results.Tcontrast([0,1]))  #doctest: +FP_6DP</span>
<span class="sd">    &lt;T contrast: effect=2.14285714286, sd=1.14062281591, t=1.87867287326,</span>
<span class="sd">    df_den=5&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(results.Fcontrast(np.eye(2)))  #doctest: +FP_6DP</span>
<span class="sd">    &lt;F contrast: F=19.4607843137, df_den=5, df_num=2&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="OLSModel.__init__"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design : array-like</span>
<span class="sd">            This is your design matrix.</span>
<span class="sd">            Data are assumed to be column ordered with</span>
<span class="sd">            observations in rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OLSModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">design</span><span class="p">)</span></div>

<div class="viewcode-block" id="OLSModel.initialize"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design</span><span class="p">):</span>
        <span class="c1"># PLEASE don&#39;t assume we have a constant...</span>
        <span class="c1"># TODO: handle case for noconstant regression</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">design</span> <span class="o">=</span> <span class="n">design</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">whiten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">calc_beta</span> <span class="o">=</span> <span class="n">npl</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized_cov_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">calc_beta</span><span class="p">,</span>
                                          <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">calc_beta</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span> <span class="o">=</span> <span class="n">matrix_rank</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_total</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span></div>

<div class="viewcode-block" id="OLSModel.logL"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.logL">[docs]</a>    <span class="k">def</span> <span class="nf">logL</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nuisance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&#39;&#39;&#39; Returns the value of the loglikelihood function at beta.</span>

<span class="sd">        Given the whitened design matrix, the loglikelihood is evaluated</span>
<span class="sd">        at the parameter vector, beta, for the dependent variable, Y</span>
<span class="sd">        and the nuisance parameter, sigma.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        beta : ndarray</span>
<span class="sd">            The parameter estimates.  Must be of length df_model.</span>
<span class="sd">        Y : ndarray</span>
<span class="sd">            The dependent variable</span>
<span class="sd">        nuisance : dict, optional</span>
<span class="sd">            A dict with key &#39;sigma&#39;, which is an optional estimate of sigma. If</span>
<span class="sd">            None, defaults to its maximum likelihood estimate (with beta fixed)</span>
<span class="sd">            as ``sum((Y - X*beta)**2) / n``, where n=Y.shape[0], X=self.design.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loglf : float</span>
<span class="sd">            The value of the loglikelihood function.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The log-Likelihood Function is defined as</span>

<span class="sd">        .. math::</span>

<span class="sd">            \ell(\beta,\sigma,Y)=</span>
<span class="sd">            -\frac{n}{2}\log(2\pi\sigma^2) - \|Y-X\beta\|^2/(2\sigma^2)</span>

<span class="sd">        The parameter :math:`\sigma` above is what is sometimes referred to as a</span>
<span class="sd">        nuisance parameter. That is, the likelihood is considered as a function</span>
<span class="sd">        of :math:`\beta`, but to evaluate it, a value of :math:`\sigma` is</span>
<span class="sd">        needed.</span>

<span class="sd">        If :math:`\sigma` is not provided, then its maximum likelihood estimate:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \hat{\sigma}(\beta) = \frac{\text{SSE}(\beta)}{n}</span>

<span class="sd">        is plugged in. This likelihood is now a function of only :math:`\beta`</span>
<span class="sd">        and is technically referred to as a profile-likelihood.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] W. Green.  &quot;Econometric Analysis,&quot; 5th ed., Pearson, 2003.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># This is overwriting an abstract method of LikelihoodModel</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span>
        <span class="n">wY</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">whiten</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">wY</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_total</span>
        <span class="n">SSE</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nuisance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sigmasq</span> <span class="o">=</span> <span class="n">SSE</span> <span class="o">/</span> <span class="n">n</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sigmasq</span> <span class="o">=</span> <span class="n">nuisance</span><span class="p">[</span><span class="s1">&#39;sigma&#39;</span><span class="p">]</span>
        <span class="n">loglf</span> <span class="o">=</span> <span class="o">-</span> <span class="n">n</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">sigmasq</span><span class="p">)</span> <span class="o">-</span> <span class="n">SSE</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigmasq</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loglf</span></div>

<div class="viewcode-block" id="OLSModel.score"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nuisance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; Gradient of the loglikelihood function at (beta, Y, nuisance).</span>

<span class="sd">        The graient of the loglikelihood function at (beta, Y, nuisance) is the</span>
<span class="sd">        score function.</span>

<span class="sd">        See :meth:`logL` for details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        beta : ndarray</span>
<span class="sd">            The parameter estimates.  Must be of length df_model.</span>
<span class="sd">        Y : ndarray</span>
<span class="sd">            The dependent variable.</span>
<span class="sd">        nuisance : dict, optional</span>
<span class="sd">            A dict with key &#39;sigma&#39;, which is an optional estimate of sigma. If</span>
<span class="sd">            None, defaults to its maximum likelihood estimate (with beta fixed)</span>
<span class="sd">            as ``sum((Y - X*beta)**2) / n``, where n=Y.shape[0], X=self.design.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        The gradient of the loglikelihood function.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># This is overwriting an abstract method of LikelihoodModel</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span>
        <span class="n">wY</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">whiten</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">wY</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_total</span>
        <span class="k">if</span> <span class="n">nuisance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">SSE</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">sigmasq</span> <span class="o">=</span> <span class="n">SSE</span> <span class="o">/</span> <span class="n">n</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sigmasq</span> <span class="o">=</span> <span class="n">nuisance</span><span class="p">[</span><span class="s1">&#39;sigma&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigmasq</span></div>

<div class="viewcode-block" id="OLSModel.information"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.information">[docs]</a>    <span class="k">def</span> <span class="nf">information</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">nuisance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; Returns the information matrix at (beta, Y, nuisance).</span>

<span class="sd">        See logL for details.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        beta : ndarray</span>
<span class="sd">            The parameter estimates.  Must be of length df_model.</span>
<span class="sd">        nuisance : dict</span>
<span class="sd">            A dict with key &#39;sigma&#39;, which is an estimate of sigma. If None,</span>
<span class="sd">            defaults to its maximum likelihood estimate (with beta fixed) as</span>
<span class="sd">            ``sum((Y - X*beta)**2) / n`` where n=Y.shape[0], X=self.design.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        info : array</span>
<span class="sd">            The information matrix, the negative of the inverse of the Hessian</span>
<span class="sd">            of the of the log-likelihood function evaluated at (theta, Y,</span>
<span class="sd">            nuisance).</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># This is overwriting an abstract method of LikelihoodModel</span>
        <span class="c1"># The subclasses WLSModel, ARModel and GLSModel all overwrite this</span>
        <span class="c1"># method. The point of these subclasses is such that not much of</span>
        <span class="c1"># OLSModel has to be changed.</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">design</span>
        <span class="n">sigmasq</span> <span class="o">=</span> <span class="n">nuisance</span><span class="p">[</span><span class="s1">&#39;sigma&#39;</span><span class="p">]</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">sigmasq</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">C</span></div>

<div class="viewcode-block" id="OLSModel.whiten"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.whiten">[docs]</a>    <span class="k">def</span> <span class="nf">whiten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Whiten design matrix</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array</span>
<span class="sd">            design matrix</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        wX : array</span>
<span class="sd">            This matrix is the matrix whose pseudoinverse is ultimately</span>
<span class="sd">            used in estimating the coefficients. For OLSModel, it is</span>
<span class="sd">            does nothing. For WLSmodel, ARmodel, it pre-applies</span>
<span class="sd">            a square root of the covariance matrix to X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">X</span></div>

<div class="viewcode-block" id="OLSModel.has_intercept"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.has_intercept">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">has_intercept</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if column of 1s is in column space of design</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">obeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">calc_beta</span><span class="p">,</span> <span class="n">o</span><span class="p">)</span>
        <span class="n">ohat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="p">,</span> <span class="n">obeta</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ohat</span><span class="p">,</span> <span class="n">o</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="OLSModel.rank"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.rank">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute rank of design matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">matrix_rank</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="p">)</span></div>

<div class="viewcode-block" id="OLSModel.fit"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.OLSModel.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fit model to data `Y`</span>

<span class="sd">        Full fit of the model including estimate of covariance matrix,</span>
<span class="sd">        (whitened) residuals and scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Y : array-like</span>
<span class="sd">            The dependent variable for the Least Squares problem.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        fit : RegressionResults</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Other estimates of the covariance matrix for a heteroscedastic</span>
        <span class="c1"># regression model can be implemented in WLSmodel. (Weighted least</span>
        <span class="c1"># squares models assume covariance is diagonal, i.e. heteroscedastic).</span>
        <span class="n">wY</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">whiten</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">calc_beta</span><span class="p">,</span> <span class="n">wY</span><span class="p">)</span>
        <span class="n">wresid</span> <span class="o">=</span> <span class="n">wY</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="n">dispersion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">wresid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">wdesign</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">lfit</span> <span class="o">=</span> <span class="n">RegressionResults</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span>
                                 <span class="n">wY</span><span class="p">,</span> <span class="n">wresid</span><span class="p">,</span> <span class="n">dispersion</span><span class="o">=</span><span class="n">dispersion</span><span class="p">,</span>
                                 <span class="n">cov</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_cov_beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lfit</span></div></div>


<div class="viewcode-block" id="ARModel"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.ARModel">[docs]</a><span class="k">class</span> <span class="nc">ARModel</span><span class="p">(</span><span class="n">OLSModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A regression model with an AR(p) covariance structure.</span>

<span class="sd">    In terms of a LikelihoodModel, the parameters</span>
<span class="sd">    are beta, the usual regression parameters,</span>
<span class="sd">    and sigma, a scalar nuisance parameter that</span>
<span class="sd">    shows up as multiplier in front of the AR(p) covariance.</span>

<span class="sd">    The linear autoregressive process of order p--AR(p)--is defined as:</span>
<span class="sd">        TODO</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from nipy.algorithms.statistics.api import Term, Formula</span>
<span class="sd">    &gt;&gt;&gt; data = np.rec.fromarrays(([1,3,4,5,8,10,9], range(1,8)),</span>
<span class="sd">    ...                          names=(&#39;Y&#39;, &#39;X&#39;))</span>
<span class="sd">    &gt;&gt;&gt; f = Formula([Term(&quot;X&quot;), 1])</span>
<span class="sd">    &gt;&gt;&gt; dmtx = f.design(data, return_float=True)</span>
<span class="sd">    &gt;&gt;&gt; model = ARModel(dmtx, 2)</span>

<span class="sd">    We go through the ``model.iterative_fit`` procedure long-hand:</span>

<span class="sd">    &gt;&gt;&gt; for i in range(6):</span>
<span class="sd">    ...     results = model.fit(data[&#39;Y&#39;])</span>
<span class="sd">    ...     print(&quot;AR coefficients:&quot;, model.rho)</span>
<span class="sd">    ...     rho, sigma = yule_walker(data[&quot;Y&quot;] - results.predicted,</span>
<span class="sd">    ...                              order=2,</span>
<span class="sd">    ...                              df=model.df_resid)</span>
<span class="sd">    ...     model = ARModel(model.design, rho) #doctest: +FP_6DP</span>
<span class="sd">    ...</span>
<span class="sd">    AR coefficients: [ 0.  0.]</span>
<span class="sd">    AR coefficients: [-0.61530877 -1.01542645]</span>
<span class="sd">    AR coefficients: [-0.72660832 -1.06201457]</span>
<span class="sd">    AR coefficients: [-0.7220361  -1.05365352]</span>
<span class="sd">    AR coefficients: [-0.72229201 -1.05408193]</span>
<span class="sd">    AR coefficients: [-0.722278   -1.05405838]</span>
<span class="sd">    &gt;&gt;&gt; results.theta #doctest: +NP_ALLCLOSE</span>
<span class="sd">    array([ 1.59564228, -0.58562172])</span>
<span class="sd">    &gt;&gt;&gt; results.t() #doctest: +NP_ALLCLOSE</span>
<span class="sd">    array([ 38.0890515 ,  -3.45429252])</span>
<span class="sd">    &gt;&gt;&gt; print(results.Tcontrast([0,1]))  #doctest: +FP_6DP</span>
<span class="sd">    &lt;T contrast: effect=-0.58562172384377043, sd=0.16953449108110835,</span>
<span class="sd">    t=-3.4542925165805847, df_den=5&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(results.Fcontrast(np.identity(2)))  #doctest: +FP_6DP</span>
<span class="sd">    &lt;F contrast: F=4216.810299725842, df_den=5, df_num=2&gt;</span>

<span class="sd">    Reinitialize the model, and do the automated iterative fit</span>

<span class="sd">    &gt;&gt;&gt; model.rho = np.array([0,0])</span>
<span class="sd">    &gt;&gt;&gt; model.iterative_fit(data[&#39;Y&#39;], niter=3)</span>
<span class="sd">    &gt;&gt;&gt; print(model.rho)  #doctest: +FP_6DP</span>
<span class="sd">    [-0.7220361  -1.05365352]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ARModel.__init__"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.ARModel.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize AR model instance</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design : ndarray</span>
<span class="sd">            2D array with design matrix</span>
<span class="sd">        rho : int or array-like</span>
<span class="sd">            If int, gives order of model, and initializes rho to zeros.  If</span>
<span class="sd">            ndarray, gives initial estimate of rho. Be careful as ``ARModel(X,</span>
<span class="sd">            1) != ARModel(X, 1.0)``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">rho</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">type</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">=</span> <span class="n">rho</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">rho</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;AR parameters must be a scalar or a vector&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ARModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">design</span><span class="p">)</span></div>

<div class="viewcode-block" id="ARModel.iterative_fit"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.ARModel.iterative_fit">[docs]</a>    <span class="k">def</span> <span class="nf">iterative_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform an iterative two-stage procedure to estimate AR(p)</span>
<span class="sd">        parameters and regression coefficients simultaneously.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Y : ndarray</span>
<span class="sd">            data to which to fit model</span>
<span class="sd">        niter : optional, int</span>
<span class="sd">            the number of iterations (default 3)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">niter</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">design</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">yule_walker</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">results</span><span class="o">.</span><span class="n">predicted</span><span class="p">,</span>
                                      <span class="n">order</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span><span class="p">)</span></div>

<div class="viewcode-block" id="ARModel.whiten"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.ARModel.whiten">[docs]</a>    <span class="k">def</span> <span class="nf">whiten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Whiten a series of columns according to AR(p) covariance structure</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_features)</span>
<span class="sd">            array to whiten</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        wX : ndarray</span>
<span class="sd">            X whitened with order self.order AR</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">_X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">):</span>
            <span class="n">_X</span><span class="p">[(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):]</span> <span class="o">=</span> <span class="n">_X</span><span class="p">[(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">_X</span></div></div>


<div class="viewcode-block" id="yule_walker"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.yule_walker">[docs]</a><span class="k">def</span> <span class="nf">yule_walker</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;unbiased&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Estimate AR(p) parameters from a sequence X using Yule-Walker equation.</span>

<span class="sd">    unbiased or maximum-likelihood estimator (mle)</span>

<span class="sd">    See, for example:</span>

<span class="sd">    http://en.wikipedia.org/wiki/Autoregressive_moving_average_model</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X :  ndarray of shape(n)</span>
<span class="sd">    order : int, optional</span>
<span class="sd">        Order of AR process.</span>
<span class="sd">    method : str, optional</span>
<span class="sd">        Method can be &quot;unbiased&quot; or &quot;mle&quot; and this determines denominator in</span>
<span class="sd">        estimate of autocorrelation function (ACF) at lag k. If &quot;mle&quot;, the</span>
<span class="sd">        denominator is n=X.shape[0], if &quot;unbiased&quot; the denominator is n-k.</span>
<span class="sd">    df : int, optional</span>
<span class="sd">        Specifies the degrees of freedom. If df is supplied, then it is assumed</span>
<span class="sd">        the X has df degrees of freedom rather than n.</span>
<span class="sd">    inv : bool, optional</span>
<span class="sd">        Whether to return the inverse of the R matrix (see code)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rho : (`order`,) ndarray</span>
<span class="sd">    sigma : int</span>
<span class="sd">        standard deviation of the residuals after fit</span>
<span class="sd">    R_inv : ndarray</span>
<span class="sd">        If `inv` is True, also return the inverse of the R matrix</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    See also</span>
<span class="sd">    http://en.wikipedia.org/wiki/AR_model#Calculation_of_the_AR_parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">method</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">method</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;unbiased&quot;</span><span class="p">,</span> <span class="s2">&quot;mle&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ACF estimation method must be &#39;unbiased or &#39;MLE&#39;&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expecting a vector to estimate AR parameters&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">-=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">df</span> <span class="ow">or</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;unbiased&quot;</span><span class="p">:</span>
        <span class="n">den</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">n</span> <span class="o">-</span> <span class="n">k</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">den</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">n</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">den</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">r</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">:])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">den</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">spl</span><span class="o">.</span><span class="n">toeplitz</span><span class="p">(</span><span class="n">r</span><span class="p">[:</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="n">spl</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">sigmasq</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="n">rho</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">inv</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rho</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigmasq</span><span class="p">),</span> <span class="n">spl</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rho</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigmasq</span><span class="p">)</span></div>


<div class="viewcode-block" id="ar_bias_corrector"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.ar_bias_corrector">[docs]</a><span class="k">def</span> <span class="nf">ar_bias_corrector</span><span class="p">(</span><span class="n">design</span><span class="p">,</span> <span class="n">calc_beta</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Return bias correcting matrix for `design` and AR order `order`</span>

<span class="sd">    There is a slight bias in the rho estimates on residuals due to the</span>
<span class="sd">    correlations induced in the residuals by fitting a linear model.  See</span>
<span class="sd">    [Worsley2002]_.</span>

<span class="sd">    This routine implements the bias correction described in appendix A.1 of</span>
<span class="sd">    [Worsley2002]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    design : array</span>
<span class="sd">        Design matrix</span>
<span class="sd">    calc_beta : array</span>
<span class="sd">        Moore-Penrose pseudoinverse of the (maybe) whitened design matrix.</span>
<span class="sd">        This is the matrix that, when applied to the (maybe whitened) data,</span>
<span class="sd">        produces the betas.</span>
<span class="sd">    order : int, optional</span>
<span class="sd">        Order p of AR(p) process</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    invM : array</span>
<span class="sd">        Matrix to bias correct estimated covariance matrix</span>
<span class="sd">        in calculating the AR coefficients</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [Worsley2002] K.J. Worsley, C.H. Liao, J. Aston, V. Petre, G.H. Duncan,</span>
<span class="sd">       F. Morales, A.C. Evans (2002) A General Statistical Analysis for fMRI</span>
<span class="sd">       Data.  Neuroimage 15:1:15</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">design</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">design</span><span class="p">,</span> <span class="n">calc_beta</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">Di</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">spl</span><span class="o">.</span><span class="n">toeplitz</span><span class="p">(</span><span class="n">I</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">Dj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">spl</span><span class="o">.</span><span class="n">toeplitz</span><span class="p">(</span><span class="n">I</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
            <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Di</span><span class="p">,</span> <span class="n">Dj</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">spl</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">M</span><span class="p">)</span></div>


<div class="viewcode-block" id="ar_bias_correct"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.ar_bias_correct">[docs]</a><span class="k">def</span> <span class="nf">ar_bias_correct</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">invM</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Apply bias correction in calculating AR(p) coefficients from `results`</span>

<span class="sd">    There is a slight bias in the rho estimates on residuals due to the</span>
<span class="sd">    correlations induced in the residuals by fitting a linear model.  See</span>
<span class="sd">    [Worsley2002]_.</span>

<span class="sd">    This routine implements the bias correction described in appendix A.1 of</span>
<span class="sd">    [Worsley2002]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    results : ndarray or results object</span>
<span class="sd">        If ndarray, assume these are residuals, from a simple model.  If a</span>
<span class="sd">        results object, with attribute ``resid``, then use these for the</span>
<span class="sd">        residuals. See Notes for more detail</span>
<span class="sd">    order : int</span>
<span class="sd">        Order ``p`` of AR(p) model</span>
<span class="sd">    invM : None or array</span>
<span class="sd">        Known bias correcting matrix for covariance.  If None, calculate from</span>
<span class="sd">        ``results.model``</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rho : array</span>
<span class="sd">        Bias-corrected AR(p) coefficients</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If `results` has attributes ``resid`` and ``scale``, then assume ``scale``</span>
<span class="sd">    has come from a fit of a potentially customized model, and we use that for</span>
<span class="sd">    the sum of squared residuals.  In this case we also need</span>
<span class="sd">    ``results.df_resid``.  Otherwise we assume this is a simple Gaussian model,</span>
<span class="sd">    like OLS, and take the simple sum of squares of the residuals.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [Worsley2002] K.J. Worsley, C.H. Liao, J. Aston, V. Petre, G.H. Duncan,</span>
<span class="sd">       F. Morales, A.C. Evans (2002) A General Statistical Analysis for fMRI</span>
<span class="sd">       Data.  Neuroimage 15:1:15</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">invM</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We need a model from ``results`` if invM is not specified</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">model</span>
        <span class="n">invM</span> <span class="o">=</span> <span class="n">ar_bias_corrector</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">design</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">calc_beta</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="s1">&#39;resid&#39;</span><span class="p">):</span>
        <span class="n">resid</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">resid</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">resid</span> <span class="o">=</span> <span class="n">results</span>
    <span class="n">in_shape</span> <span class="o">=</span> <span class="n">resid</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Allows results residuals to have shapes other than 2D.  This allows us to</span>
    <span class="c1"># use this routine for image data as well as more standard 2D model data</span>
    <span class="n">resid</span> <span class="o">=</span> <span class="n">resid</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_features</span><span class="p">,</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># glm.Model fit methods fill in a ``scale`` estimate. For simpler</span>
    <span class="c1"># models, there is no scale estimate written into the results.</span>
    <span class="c1"># However, the same calculation resolves (with Gaussian family)</span>
    <span class="c1"># to ``np.sum(resid**2) / results.df_resid``.</span>
    <span class="c1"># See ``estimate_scale`` from glm.Model</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="s1">&#39;scale&#39;</span><span class="p">):</span>
        <span class="n">sum_sq</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">resid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">*</span> <span class="n">results</span><span class="o">.</span><span class="n">df_resid</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># No scale in results</span>
        <span class="n">sum_sq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">sum_sq</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_sq</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">cov</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span> <span class="o">*</span> <span class="n">resid</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span> <span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># cov is shape (order + 1, V) where V = np.product(in_shape[1:])</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">invM</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="n">pos_recipr</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">order</span><span class="p">,)</span> <span class="o">+</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span></div>


<div class="viewcode-block" id="AREstimator"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.AREstimator">[docs]</a><span class="k">class</span> <span class="nc">AREstimator</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to estimate AR(p) coefficients from residuals</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AREstimator.__init__"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.AREstimator.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Bias-correcting AR estimation class</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : ``OSLModel`` instance</span>
<span class="sd">            A models.regression.OLSmodel instance,</span>
<span class="sd">            where `model` has attribute ``design``</span>
<span class="sd">        p : int, optional</span>
<span class="sd">            Order of AR(p) noise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">invM</span> <span class="o">=</span> <span class="n">ar_bias_corrector</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">design</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">calc_beta</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Calculate AR(p) coefficients from `results`.``residuals``</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        results : Results instance</span>
<span class="sd">            A models.model.LikelihoodModelResults instance</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ar_p : array</span>
<span class="sd">            AR(p) coefficients</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">ar_bias_correct</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">invM</span><span class="p">)</span></div>


<div class="viewcode-block" id="WLSModel"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.WLSModel">[docs]</a><span class="k">class</span> <span class="nc">WLSModel</span><span class="p">(</span><span class="n">OLSModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A regression model with diagonal but non-identity covariance structure.</span>

<span class="sd">    The weights are presumed to be (proportional to the) inverse</span>
<span class="sd">    of the variance of the observations.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from nipy.algorithms.statistics.api import Term, Formula</span>
<span class="sd">    &gt;&gt;&gt; data = np.rec.fromarrays(([1,3,4,5,2,3,4], range(1,8)),</span>
<span class="sd">    ...                          names=(&#39;Y&#39;, &#39;X&#39;))</span>
<span class="sd">    &gt;&gt;&gt; f = Formula([Term(&quot;X&quot;), 1])</span>
<span class="sd">    &gt;&gt;&gt; dmtx = f.design(data, return_float=True)</span>
<span class="sd">    &gt;&gt;&gt; model = WLSModel(dmtx, weights=range(1,8))</span>
<span class="sd">    &gt;&gt;&gt; results = model.fit(data[&#39;Y&#39;])</span>
<span class="sd">    &gt;&gt;&gt; results.theta</span>
<span class="sd">    array([ 0.0952381 ,  2.91666667])</span>
<span class="sd">    &gt;&gt;&gt; results.t()</span>
<span class="sd">    array([ 0.35684428,  2.0652652 ])</span>
<span class="sd">    &gt;&gt;&gt; print(results.Tcontrast([0,1]))  #doctest: +FP_6DP</span>
<span class="sd">    &lt;T contrast: effect=2.91666666667, sd=1.41224801095, t=2.06526519708,</span>
<span class="sd">    df_den=5&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(results.Fcontrast(np.identity(2)))  #doctest: +FP_6DP</span>
<span class="sd">    &lt;F contrast: F=26.9986072423, df_den=5, df_num=2&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WLSModel.__init__"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.WLSModel.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span> <span class="c1"># scalar</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">design_rows</span> <span class="o">=</span> <span class="n">design</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">design_rows</span> <span class="ow">and</span>
                   <span class="n">weights</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">design_rows</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;Weights must be scalar or same length as design&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">design_rows</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WLSModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">design</span><span class="p">)</span></div>

<div class="viewcode-block" id="WLSModel.whiten"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.WLSModel.whiten">[docs]</a>    <span class="k">def</span> <span class="nf">whiten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Whitener for WLS model, multiplies by sqrt(self.weights)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">v</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">c</span>
            <span class="k">return</span> <span class="n">v</span></div></div>


<div class="viewcode-block" id="RegressionResults"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults">[docs]</a><span class="k">class</span> <span class="nc">RegressionResults</span><span class="p">(</span><span class="n">LikelihoodModelResults</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class summarizes the fit of a linear regression model.</span>

<span class="sd">    It handles the output of contrasts, estimates of covariance, etc.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RegressionResults.__init__"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">wY</span><span class="p">,</span> <span class="n">wresid</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dispersion</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">nuisance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;See LikelihoodModelResults constructor.</span>

<span class="sd">        The only difference is that the whitened Y and residual values</span>
<span class="sd">        are stored for a regression model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">LikelihoodModelResults</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span>
                                        <span class="n">dispersion</span><span class="p">,</span> <span class="n">nuisance</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wY</span> <span class="o">=</span> <span class="n">wY</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wresid</span> <span class="o">=</span> <span class="n">wresid</span></div>

<div class="viewcode-block" id="RegressionResults.resid"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.resid">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">resid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Residuals from the fit.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicted</span></div>

<div class="viewcode-block" id="RegressionResults.norm_resid"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.norm_resid">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">norm_resid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Residuals, normalized to have unit length.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Is this supposed to return &quot;stanardized residuals,&quot;</span>
<span class="sd">        residuals standardized</span>
<span class="sd">        to have mean zero and approximately unit variance?</span>

<span class="sd">        d_i = e_i / sqrt(MS_E)</span>

<span class="sd">        Where MS_E = SSE / (n - k)</span>

<span class="sd">        See: Montgomery and Peck 3.2.1 p. 68</span>
<span class="sd">             Davidson and MacKinnon 15.2 p 662</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">resid</span> <span class="o">*</span> <span class="n">pos_recipr</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dispersion</span><span class="p">))</span></div>

<div class="viewcode-block" id="RegressionResults.predicted"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.predicted">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">predicted</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Return linear predictor values from a design matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>
        <span class="c1"># the LikelihoodModelResults has parameters named &#39;theta&#39;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">design</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span></div>

<div class="viewcode-block" id="RegressionResults.R2_adj"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.R2_adj">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">R2_adj</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the R^2 value for each row of the response Y.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Changed to the textbook definition of R^2.</span>

<span class="sd">        See: Davidson and MacKinnon p 74</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">has_intercept</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;model does not have intercept term, &quot;</span> <span class="o">+</span>\
                          <span class="s2">&quot;SST inappropriate&quot;</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">R2</span>
        <span class="n">d</span> <span class="o">*=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">df_total</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">d</span></div>

<div class="viewcode-block" id="RegressionResults.R2"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.R2">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">R2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the adjusted R^2 value for each row of the response Y.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Changed to the textbook definition of R^2.</span>

<span class="sd">        See: Davidson and MacKinnon p 74</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SSE</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">SST</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">d</span></div>

<div class="viewcode-block" id="RegressionResults.SST"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.SST">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">SST</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Total sum of squares. If not from an OLS model this is &quot;pseudo&quot;-SST.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">has_intercept</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;model does not have intercept term, &quot;</span> <span class="o">+</span>\
                          <span class="s2">&quot;SST inappropriate&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">wY</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">wY</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="RegressionResults.SSE"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.SSE">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">SSE</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Error sum of squares. If not from an OLS model this is &quot;pseudo&quot;-SSE.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wresid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="RegressionResults.SSR"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.SSR">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">SSR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Regression sum of squares &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">SST</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">SSE</span></div>

<div class="viewcode-block" id="RegressionResults.MSR"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.MSR">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">MSR</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Mean square (regression)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">SSR</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_model</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="RegressionResults.MSE"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.MSE">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">MSE</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Mean square (error) &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">SSE</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span></div>

<div class="viewcode-block" id="RegressionResults.MST"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.MST">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">MST</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Mean square (total)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">SST</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_total</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="RegressionResults.F_overall"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.RegressionResults.F_overall">[docs]</a>    <span class="nd">@setattr_on_read</span>
    <span class="k">def</span> <span class="nf">F_overall</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Overall goodness of fit F test,</span>
<span class="sd">        comparing model to a model with just an intercept.</span>
<span class="sd">        If not an OLS model this is a pseudo-F.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">MSR</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">MSE</span>
        <span class="n">Fp</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="n">F</span><span class="p">,</span> <span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">Fp</span><span class="p">,</span> <span class="s1">&#39;df_num&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_model</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="s1">&#39;df_den&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_resid</span><span class="p">}</span></div></div>


<div class="viewcode-block" id="GLSModel"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.GLSModel">[docs]</a><span class="k">class</span> <span class="nc">GLSModel</span><span class="p">(</span><span class="n">OLSModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generalized least squares model with a general covariance structure</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GLSModel.__init__"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.GLSModel.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cholsigmainv</span> <span class="o">=</span> <span class="n">npl</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">npl</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">sigma</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GLSModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">design</span><span class="p">)</span></div>

<div class="viewcode-block" id="GLSModel.whiten"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.GLSModel.whiten">[docs]</a>    <span class="k">def</span> <span class="nf">whiten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cholsigmainv</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="isestimable"><a class="viewcode-back" href="../../../../../api/generated/nipy.algorithms.statistics.models.regression.html#nipy.algorithms.statistics.models.glm.isestimable">[docs]</a><span class="k">def</span> <span class="nf">isestimable</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; True if (Q, P) contrast `C` is estimable for (N, P) design `D`</span>

<span class="sd">    From an Q x P contrast matrix `C` and an N x P design matrix `D`, checks if</span>
<span class="sd">    the contrast `C` is estimable by looking at the rank of ``vstack([C,D])``</span>
<span class="sd">    and verifying it is the same as the rank of `D`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C : (Q, P) array-like</span>
<span class="sd">        contrast matrix. If `C` has is 1 dimensional assume shape (1, P)</span>
<span class="sd">    D: (N, P) array-like</span>
<span class="sd">        design matrix</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf : bool</span>
<span class="sd">        True if the contrast `C` is estimable on design `D`</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; D = np.array([[1, 1, 1, 0, 0, 0],</span>
<span class="sd">    ...               [0, 0, 0, 1, 1, 1],</span>
<span class="sd">    ...               [1, 1, 1, 1, 1, 1]]).T</span>
<span class="sd">    &gt;&gt;&gt; isestimable([1, 0, 0], D)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; isestimable([1, -1, 0], D)</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">C</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">if</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Contrast should have </span><span class="si">%d</span><span class="s1"> columns&#39;</span> <span class="o">%</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">matrix_rank</span><span class="p">(</span><span class="n">new</span><span class="p">)</span> <span class="o">!=</span> <span class="n">matrix_rank</span><span class="p">(</span><span class="n">D</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright J. Taylor and others
      <span class="lastupdated">
        Last updated on Sep 25, 2019.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>